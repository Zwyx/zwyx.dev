"use strict";(self.webpackChunkzwyx_dev=self.webpackChunkzwyx_dev||[]).push([[8130],{7735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"docker-dev","metadata":{"permalink":"/blog/docker-dev","editUrl":"https://github.com/zwyx/zwyx.dev/tree/master/blog/2025-11-27-docker-dev/index.mdx","source":"@site/blog/2025-11-27-docker-dev/index.mdx","title":"Protect yourself from malicious NPM packages with a system-wide dev container","description":"Isolate Node.js development from your host system using a persistent Docker container.","date":"2025-11-27T00:00:00.000Z","tags":[{"inline":true,"label":"docker","permalink":"/blog/tags/docker"},{"inline":true,"label":"security","permalink":"/blog/tags/security"},{"inline":true,"label":"npm","permalink":"/blog/tags/npm"},{"inline":true,"label":"node","permalink":"/blog/tags/node"},{"inline":true,"label":"vscode","permalink":"/blog/tags/vscode"}],"readingTime":10.4,"hasTruncateMarker":true,"authors":[{"name":"Alex","title":"Web developer","email":"alex@zwyx.dev","url":"https://github.com/Zwyx","imageURL":"https://github.com/zwyx.png","key":"alex","page":null}],"frontMatter":{"slug":"docker-dev","title":"Protect yourself from malicious NPM packages with a system-wide dev container","description":"Isolate Node.js development from your host system using a persistent Docker container.","authors":["alex"],"tags":["docker","security","npm","node","vscode"]},"unlisted":false,"nextItem":{"title":"Base conversions with BIG numbers in JavaScript","permalink":"/blog/base-conversions-with-big-numbers-in-javascript"}},"content":"import { Image } from \\"@site/src/components/Image\\";\\nimport sublimeMerge from \\"./sublimeMerge.webp\\";\\nimport terminal from \\"./terminal.webp\\";\\nimport vscodeSettingsInContainer from \\"./vscodeSettingsInContainer.webp\\";\\nimport vscodeWindowCustomisation from \\"./vscodeWindowCustomisation.webp\\";\\n\\nRun a **single Docker container** that stays active, and drop into it whenever you need to work on a Node project. This \\"system-wide\\" container:\\n\\n- **starts once** and stays running: no startup time and less disk space, compared to regular per-project dev containers,\\n- **is used to work on multiple projects**: attach as many VS Code windows as you want to it,\\n- **isolates NPM packages** from your host system.\\n\\n{/* truncate */}\\n\\n:::tip[Motivation]\\nNPM supply chain attacks are increasingly common. Recently, the multiple [Shai-Hulud](https://www.koi.ai/incident/shai-hulud-npm-supply-chain-attack-crowdstrike-tinycolor) campaigns compromised many packages including some belonging to CrowdStrike, Zapier, PostHog, Postman, and [many others](https://www.wiz.io/blog/shai-hulud-2-0-ongoing-supply-chain-attack).\\n\\nNode.js hasn\'t been built with security in mind: any script, any dependency, has full access to the user\'s environment (file system, network, etc. which easily leads to credentials theft). Node\'s author himself recognised this and created [Deno and its system of permissions](https://deno.com/learn/nodes-security-problem) for this reason.\\n\\nA way to make working with Node more secure is to use a [dev container](https://code.visualstudio.com/docs/devcontainers/containers): a Docker container inside which we run all our NPM commands and Node scripts. This isolates them from our host machine and drastically limits the damage in case of compromise.\\n\\nHowever, with many projects, creating one dev container for each can quickly become cumbersome.\\n\\n**The solution presented here is to create a single, persistent, \\"system-wide\\" development container, inside which we will open all our projects.**\\n:::\\n\\n## Setup\\n\\n:::info[Note]\\nWorking inside a dev container doesn\'t create any overhead on Linux, as Docker works natively there. If you use another system, your experience might be different.\\n:::\\n\\nThe full implementation is called Docker Dev and is available at [github.com/zwyx/docker-dev](https://github.com/zwyx/docker-dev).\\n\\nFirst, you\'ll need to set up [Docker](https://docs.docker.com/engine/install/) if you don\'t have it already.\\n\\nThen, clone the Docker Dev repository:\\n\\n```bash\\ngit clone https://github.com/zwyx/docker-dev.git\\ncd docker-dev\\n```\\n\\nOpen the file `docker-compose.yml`, and modify the following line:\\n\\n```yml\\n- ~/dev:/home/${USER}/dev\\n```\\n\\nto replace `dev` with the name of your main workspace folder (containing all your repositories). The goal is for all your projects to have the **same path on your host machine and inside the container**. This will make **switching from any directory on your host to the same directory inside the container** very easy.\\n\\nDo the same in the `Dockerfile`:\\n\\n```dockerfile\\nWORKDIR /home/${USERNAME}/dev\\n```\\n\\n:::note\\nIf you\'re on a Mac, also replace `/home` with `/Users` everywhere in these two files.\\n:::\\n\\nNow, start the container:\\n\\n```bash\\ndocker-compose up -d\\n```\\n\\n:::info[Note]\\nThis container is quite tied to my personal configuration and preferences. If something doesn\'t work, open `Dockerfile` and `docker-compose.yml` to make any necessary adjustments.\\n:::\\n\\n## Terminal integration\\n\\nOn your host machine, add this alias to your `~/.zshrc` (or equivalent):\\n\\n```bash\\nalias d=\'docker exec -it -w \\"$PWD\\" dev zsh\'\\n```\\n\\nNow, if you have correctly configured your workspace folder during the previous step, you can navigate to any project or subdirectory inside it, and simply run:\\n\\n```bash\\nd\\n```\\n\\nto open a **terminal session inside the dev container, at the same location**:\\n\\n<Image\\n\\tsrc={terminal}\\n\\talt=\\"Terminal session inside our dev container.\\"\\n\\tlegend=\\"Docker Dev is preconfigured with ZSH and a theme allowing to instantly recognise that a terminal session is running inside the container.\\"\\n\\tborderRadius=\\"5px\\"\\n/>\\n\\n## VS Code integration\\n\\n### Attach the first window\\n\\nInstall the official [Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) extension.\\n\\nThen in VS Code, open the command palette, run **Dev Containers: Attach to Running Container...** and select the container `dev`.\\n\\nNow open a project\'s folder in this window, and that\'s it: you can start working with the same dev environment you\'re used to.\\n\\nSome VS Code extensions, like Prettier and ESLint, need to run inside the container. Simply open the Extensions view in your sidebar and click **Install in container** on the extensions you wish to use.\\n\\n:::info[Note]\\nHaving **extensions running inside the container is a great security improvement** because VS Code extensions, like NPM packages, [have full access to your system and can be compromised](https://www.koi.ai/blog/1-6-how-we-hacked-multi-billion-dollar-companies-in-30-minutes-using-a-fake-vscode-extension). Even worse: VS Code, by default, auto-updates them! Which means, if an extension gets compromised, it could land on your machine without you doing anything.\\n\\nSo having extensions running inside the container is much safer: compromised extensions won\'t have access to your host system.\\n\\nHowever: **not all extensions run inside the container**. Some extensions, like themes, always run on the UI on your host machine, so they do have access to your system. I highly recommend to **disable auto-update for these extensions**, and to update them manually when nothing is going on in the news.\\n:::\\n\\n### Attach multiple windows\\n\\nYou can have as many projects as you want opened simultaneously, each on its own VS Code window attached to the container.\\n\\nHowever, if a VS Code window is already attached to the container, then running again the command **Dev Containers: Attach to Running Container...** will simply focus the existing window, which can be confusing.\\n\\nTo make things simpler, set the VS Code setting `window.openFoldersInNewWindow` to `on`.\\n\\nNow, in a window that is already attached to the container, run the command **File: Open Folder...**, select the folder of another project you\'d like to open, and press Enter. A new window \u2013 also attached to the container \u2013 will open with this project.\\n\\nSet a keyboard shortcut for this command, for convenience. (I set `Ctrl+O`, as I only use `Ctrl+P` to open files.)\\n\\n### Visual differentiation\\n\\nYou can decorate windows that are attached to the container differently than regular windows, to quickly distinguish them.\\n\\nFor instance, you can make the window\'s title start with a package \ud83d\udce6 icon, and colour its title bar:\\n\\n<Image\\n\\tsrc={vscodeWindowCustomisation}\\n\\talt=\\"Two VS Code windows with different customisation to differentiate containerised applications.\\"\\n\\tlegend={\\n\\t\\t<span>\\n\\t\\t\\t<code>docker-dev</code> is a regular window, <code>zwyx.dev</code> is\\n\\t\\t\\tattached to the container\\n\\t\\t</span>\\n\\t}\\n\\twidth=\\"500\\"\\n\\tborderRadius=\\"5px\\"\\n/>\\n\\nOpen VS Code\'s settings and select the **Remote** tab. Settings in this tab apply only to windows that are attached to the container:\\n\\n<Image\\n\\tsrc={vscodeSettingsInContainer}\\n\\talt=\\"VS Code allows to customise settings inside a dev container.\\"\\n\\tborderRadius=\\"5px\\"\\n/>\\n\\nThese settings are saved in `~/.vscode-server/data/Machine/settings.json` in the container\'s file system. Docker Dev includes an example copy of this file, which is copied to the correct location during the container\'s creation (see the `Dockerfile`).\\n\\n### Ports\\n\\nNow that you have your container, you\'ll want to run everything Node-related inside it (`npm i`, `npm run dev`, etc.).\\n\\nTo run web applications, you\'ll need to expose their ports to be able to access them from your browser on your host machine.\\n\\nWe could configure the ports in the `docker-compose.yml` file, but exposing ports this way can only be done before the container starts. It cannot be changed while it is running.\\n\\nA more practical solution is to **use VS Code to forward our ports**. Contrary to Docker, VS Code can start and stop forwarding ports while the container is running.\\n\\nOpen the command palette and run **Forward a port**, enter the port number, and press Enter. For example, I am forwarding port `3000` to run Docusaurus as I\'m writing this blog post, to preview it in my browser.\\n\\nNote that some dev servers require an additional argument for container networking, usually `--host 0.0.0.0`. Docker Dev is configured with a few useful aliases, such as:\\n\\n```bash\\nalias nrd=\'npm run dev -- --host 0.0.0.0\'\\n```\\n\\n### Trash\\n\\nOn your host machine, deleting a file from VS Code\'s File Explorer usually sends this file to your system\'s trash.\\n\\nInside a container however, VS Code isn\'t able to do this by default, and deletes files permanently instead.\\n\\nIf you want to have the trash functionality inside your container, **install the [Remote Trash](https://marketplace.visualstudio.com/items?itemName=Zwyx.remotetrash) extension**. (Docker Dev is already configured with `trash-cli`, which is required for this extension to work.)\\n\\n## NVM\\n\\nDocker Dev comes preconfigured with NVM to manage your Node versions. To avoid taking up extra space unnecessarily, it **uses the downloaded Node versions already present on your host machine**. (See in `docker-compose.yml`, the line `- ~/.nvm:/home/${USER}/.nvm` that mounts your host\'s `~/.nvm` folder inside the container.)\\n\\n## Advanced features\\n\\n### Integration with other applications\\n\\nDocker Dev provides useful scripts to integrate it with other applications (Git clients, etc.).\\n\\nUse the script `docker-dev/misc/open-in-vscode.sh` to configure the external editor of any application that supports it. For instance with [Sublime Merge](https://www.sublimemerge.com):\\n\\n<Image\\n\\tsrc={sublimeMerge}\\n\\talt=\\"Sublime Merge external editor configuration.\\"\\n\\tlegend=\\"Sublime Merge external editor configuration\\"\\n\\tborderRadius=\\"5px\\"\\n/>\\n\\n`open-in-vscode.sh` **resolves the closest Git repository** from the path passed as argument (or the current working directory if no argument is provided), and opens it in **either a VS Code window attached to the dev container, or a regular one if the directory contains a file named `.nocontainer`**. (If a window on this project is already open, VS Code will simply focus it.)\\n\\nAnother script \u2013 `docker-dev/misc/open-in-terminal.sh` \u2013 opens the path passed as argument in either a terminal session inside the dev container, or a regular one if the directory contains a file named `.nocontainer`.\\n\\nIf you need to create `.nocontainer` files, but you\'d prefer not to commit them or add them to every project\'s `.gitignore`, you can simply add `.nocontainer` to your global ignore file:\\n\\n```ignore title=\\"~/.config/git/ignore\\"\\n.nocontainer\\n```\\n\\n### Host command execution\\n\\nThe scripts in the previous section allow you to open VS Code inside the dev container from another application. But how to do the opposite: open an external application from inside the dev container?\\n\\nThe **Host command execution** feature of Docker Dev addresses exactly this: it allows to **execute commands on the host machine from within the container**.\\n\\nIt uses a messaging system with a service that watches for command requests from the container and executes them on the host.\\n\\n#### Setup\\n\\n1. Install `inotify-tools`:\\n\\n```bash\\nsudo apt install inotify-tools\\n```\\n\\n2. Make sure the watcher script is executable:\\n\\n```bash\\nchmod +x host-exec-service/host-exec.sh\\n```\\n\\n3. Install and start the systemd service \u2013 replace `<path-to-docker-dev>` below:\\n\\n```bash\\nmkdir -p ~/.config/systemd/user\\nln -s \\"<path-to-docker-dev>/host-exec-service/host-exec.service\\" ~/.config/systemd/user/\\nsystemctl --user daemon-reload\\nsystemctl --user enable host-exec.service\\nsystemctl --user start host-exec.service\\n```\\n\\n4. Recreate the container, for the volume `~/.docker-dev` to be mounted:\\n\\n```bash\\ndocker-compose up --build -d\\n```\\n\\n#### Make your own commands\\n\\nCreate `host-exec-xxx` files specific to your use case (like the ones in `docker-dev/container-content`) and adapt the file `docker-dev/host-exec-service/host-exec.sh` (mainly the array `ALLOWED_COMMANDS` \u2013 restart the service after modifying this file: `systemctl --user restart host-exec.service`).\\n\\nFor instance, the file `host-exec-sublime-merge` allows to open Sublime Merge from a VS Code window attached to the container. It uses the extension [History in Sublime Merge](https://marketplace.visualstudio.com/items?itemName=adhamu.history-in-sublime-merge), with its setting `history-in-sublime-merge.path` in the container set to `host-exec-sublime-merge`. It also requires a script `open-in-sublime-merge.sh` (see `host-exec.sh`).\\n\\n#### Security aspects to keep in mind\\n\\nMake sure the host command execution service maintains the following features in order to prevent malicious scripts from escaping the container:\\n\\n- **Whitelist-based**: only approved commands can be executed.\\n- **Path validation**: commands can only target directories under your main workspace folder.\\n- **Arguments validation**: arguments are only allowed for specific, safe commands.\\n- **Shell injection prevention**: potentially dangerous characters are blocked.\\n\\n## Final thoughts\\n\\nSetting up this system takes 20-30 minutes. In exchange, you get:\\n\\n- **Protection** from malicious NPM packages that could compromise your system.\\n- **Peace of mind** when installing dependencies from unfamiliar packages.\\n- **Instant access** to a consistent development environment.\\n- **Flexibility** to opt out specific projects with a simple `.nocontainer` file.\\n\\nFor anyone who frequently works with Node.js projects, especially those involving third-party packages or untrusted code, this setup provides a significant security improvement with minimal overhead.\\n\\nGive it a try at [github.com/zwyx/docker-dev](https://github.com/zwyx/docker-dev)."},{"id":"base-conversions-with-big-numbers-in-javascript","metadata":{"permalink":"/blog/base-conversions-with-big-numbers-in-javascript","editUrl":"https://github.com/zwyx/zwyx.dev/tree/master/blog/2024-02-06-base-conversions-with-big-numbers-in-javascript/index.mdx","source":"@site/blog/2024-02-06-base-conversions-with-big-numbers-in-javascript/index.mdx","title":"Base conversions with BIG numbers in JavaScript","description":"How to rapidly convert very big numbers from one base to another in JavaScript.","date":"2024-02-06T00:00:00.000Z","tags":[{"inline":true,"label":"base conversion","permalink":"/blog/tags/base-conversion"},{"inline":true,"label":"v8","permalink":"/blog/tags/v-8"},{"inline":true,"label":"integer","permalink":"/blog/tags/integer"},{"inline":true,"label":"bigint","permalink":"/blog/tags/bigint"},{"inline":true,"label":"string","permalink":"/blog/tags/string"},{"inline":true,"label":"algorithm","permalink":"/blog/tags/algorithm"},{"inline":true,"label":"javascript","permalink":"/blog/tags/javascript"}],"readingTime":4.97,"hasTruncateMarker":true,"authors":[{"name":"Alex","title":"Web developer","email":"alex@zwyx.dev","url":"https://github.com/Zwyx","imageURL":"https://github.com/zwyx.png","key":"alex","page":null}],"frontMatter":{"slug":"base-conversions-with-big-numbers-in-javascript","title":"Base conversions with BIG numbers in JavaScript","description":"How to rapidly convert very big numbers from one base to another in JavaScript.","authors":["alex"],"tags":["base conversion","v8","integer","bigint","string","algorithm","javascript"]},"unlisted":false,"prevItem":{"title":"Protect yourself from malicious NPM packages with a system-wide dev container","permalink":"/blog/docker-dev"},"nextItem":{"title":"Type-safe translations with TypeScript and i18next","permalink":"/blog/typesafe-translations"}},"content":"For the [Library of Babel](https://babel.zwyx.dev), I needed to convert very big numbers \u2014 hundreds of thousands of digits \u2014 from a base to another.\\n\\n{/* truncate */}\\n\\nHowever, `BigInt` is limited:\\n\\n- from string \u2192 the constructor `BigInt()` accepts strings in bases 2, 8, 10, and 16, only;\\n- to string \u2192 `toString()` accepts a base of between 2 and 36.\\n\\nI needed to work with bases 29 and 94, `BigInt` wasn\'t able to handle this. So I tried to implement the necessary algorithms in JavaScript.\\n\\n## From string\\n\\nTo convert a **string to an integer**, the classic algorithm is:\\n\\n```ts\\nconst fromBase = (text: string, alphabet: string = \\"0123456789\\"): bigint => {\\n\\tconst base = BigInt(alphabet.length);\\n\\n\\tlet result = 0n;\\n\\n\\t// Start from the left of the string\\n\\tfor (let i = 0; i < text.length; i++) {\\n\\t\\t// for each digit, take the previous result,\\n\\t\\t// multiply it by the base, and add the new digit\\n\\t\\tresult = result * base + BigInt(alphabet.indexOf(text.charAt(i)));\\n\\t}\\n\\n\\t/* or we could do that, but it\'s slower:\\n\\t// starting from the right of the string\\n\\tfor (let i = text.length - 1; i >= 0; i--) {\\n\\t\\t// multiply each digit by the base to the power of\\n\\t\\t// the digit position, and add it to the result\\n\\t\\tresult +=\\n\\t\\t\\tBigInt(alphabet.indexOf(text.charAt(i))) *\\n\\t\\t\\tbase ** BigInt(text.length - 1 - i);\\n\\t}\\n\\t*/\\n\\n\\treturn result;\\n};\\n```\\n\\nHowever, this is quite slow: it takes **30s** on my machine to convert a string containing **500,000 random digits in base 10**. (I tried to compile it to WebAssembly with AssemblyScript, but it made it even slower.)\\n\\nWhereas it takes V8\'s `BigInt` only **100ms**!\\n\\nTurns out, `BigInt` uses a different algorithm, which can be found in V8\'s [`FromStringLarge`](https://github.com/v8/v8/blob/19853e10095df4aa640d6d3377c532c8a22ae1c5/src/bigint/fromstring.cc#L50) function.\\n\\nI\'ll leave it to you to read the description in V8\'s source code to understand how it works, and here is my JavaScript version:\\n\\n```ts\\nconst fromBase = (text: string, alphabet: string = \\"0123456789\\"): bigint => {\\n\\tconst base = BigInt(alphabet.length);\\n\\n\\tlet parts = text\\n\\t\\t.split(\\"\\")\\n\\t\\t.map((part) => [BigInt(alphabet.indexOf(part)), base]);\\n\\n\\tif (parts.length === 1) {\\n\\t\\treturn parts[0][0];\\n\\t}\\n\\n\\tlet pairFull: boolean;\\n\\twhile (parts.length > 2) {\\n\\t\\tpairFull = false;\\n\\t\\tparts = parts.reduce<bigint[][]>((acc, cur, i) => {\\n\\t\\t\\tif (!pairFull) {\\n\\t\\t\\t\\tif (i === parts.length - 1) {\\n\\t\\t\\t\\t\\tacc.push(cur);\\n\\t\\t\\t\\t} else {\\n\\t\\t\\t\\t\\tacc.push([\\n\\t\\t\\t\\t\\t\\tcur[0] * parts[i + 1][1] + parts[i + 1][0],\\n\\t\\t\\t\\t\\t\\tcur[1] * parts[i + 1][1],\\n\\t\\t\\t\\t\\t]);\\n\\t\\t\\t\\t\\tpairFull = true;\\n\\t\\t\\t\\t}\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tpairFull = false;\\n\\t\\t\\t}\\n\\t\\t\\treturn acc;\\n\\t\\t}, []);\\n\\t}\\n\\n\\treturn parts[0][0] * parts[1][1] + parts[1][0];\\n};\\n```\\n\\nIt now takes **120ms** to do the conversion! Just slightly slower than native `BigInt`. (And without any optimisations that are mentioned in V8\'s code.)\\n\\nIt\'s a bit counter intuitive, because this algorithm does about 1,000,000 iterations, instead of 500,000 for the classic algorithm (which does one for each digit). The reason is apparently that the multiplications are smaller, and possibly more optimisable because involving parts of the same size.\\n\\n## To string\\n\\nTo convert an **integer to a string**, the classic algorithm is the successive division method:\\n\\n```ts\\nconst toBase = (value: bigint, alphabet: string = \\"0123456789\\"): string => {\\n\\tconst base = BigInt(alphabet.length);\\n\\n\\tlet result = \\"\\";\\n\\n\\t// At start, the dividend is equal to the value\\n\\tlet dividend = value;\\n\\tlet remainder;\\n\\n\\twhile (dividend >= base) {\\n\\t\\t// We get the remainder of the dividend modulo the base\\n\\t\\tremainder = dividend % base;\\n\\t\\t// and we append it to the result, from right to left\\n\\t\\tresult = alphabet[Number(remainder)] + result;\\n\\t\\t// then we divide the dividend by the base\\n\\t\\t// and that gives us the dividend for the next iteration\\n\\t\\tdividend = dividend / base;\\n\\t}\\n\\tresult = alphabet[Number(dividend)] + result;\\n\\n\\treturn result;\\n};\\n```\\n\\nHowever, this is again quite slow: 30s to convert a bigint of 500,000 random digits in base 10.\\n\\nFor this too, V8\'s `BigInt` is much faster, and uses a different algorithm, [_divide-and-conquer conversion_](https://github.com/v8/v8/blob/19853e10095df4aa640d6d3377c532c8a22ae1c5/src/bigint/tostring.cc#L275).\\n\\nI recommend again to read the description in V8\'s code, as I couldn\'t explain it better, and here is my JavaScript version:\\n\\n```ts\\nconst toBase = (value: bigint, alphabet: string = \\"0123456789\\"): string => {\\n\\tconst base = BigInt(alphabet.length);\\n\\n\\tlet result = \\"\\";\\n\\n\\tconst divisors = [base];\\n\\n\\tconst numberOfBitsInValue = value.toString(2).length;\\n\\n\\twhile (divisors.at(-1).toString(2).length * 2 - 1 <= numberOfBitsInValue) {\\n\\t\\tdivisors.push(divisors.at(-1) ** 2n);\\n\\t}\\n\\n\\tconst divide = (dividend: bigint, divisorIndex: number) => {\\n\\t\\tconst divisor = divisors[divisorIndex];\\n\\n\\t\\tconst remainder = dividend % divisor;\\n\\t\\tconst newDividend = dividend / divisor;\\n\\n\\t\\tif (divisorIndex > 0) {\\n\\t\\t\\tdivide(remainder, divisorIndex - 1);\\n\\t\\t\\tdivide(newDividend, divisorIndex - 1);\\n\\t\\t} else {\\n\\t\\t\\tresult = `${alphabet[Number(newDividend)]}${\\n\\t\\t\\t\\talphabet[Number(remainder)]\\n\\t\\t\\t}${result}`;\\n\\t\\t}\\n\\t};\\n\\n\\tdivide(value, divisors.length - 1, true);\\n\\n\\tresult = result.replace(new RegExp(`^${alphabet[0]}*`), \\"\\");\\n\\n\\treturn result;\\n};\\n```\\n\\nIt now takes **150ms** to do the conversion! (Also without any optimisations.)\\n\\n---\\n\\nAnd that\'s it. These two fast algorithms made possible my version of the [the Library of Babel](https://babel.zwyx.dev), which works entirely client-side.\\n\\n## Unexpected turn of events!\\n\\nThanks to these algorithms, I was able to finish the [the Library of Babel](https://babel.zwyx.dev). Every operation was taking a couple of seconds, at most, on my computer.\\n\\nHowever, when testing the app on my phone, I realised that one operation was very slow: it took more than 3 minutes!\\n\\nIt turned out that it was a `.toString()` call on a very large bigint. The need was to convert this bigint to a string in base 10, so I didn\'t bother changing this `.toString()` to use the new algorithm `toBase`, because `.toString()` is able to handle base 10.\\n\\nHowever, V8\'s [source code](https://github.com/v8/v8/blob/main/src/bigint/tostring.cc) shows that the fast `.toString` algorithm is behind the flag `V8_ADVANCED_BIGINT_ALGORITHMS`.\\n\\nI guess this flag is ON when Chrome is built for Linux desktop, but OFF when it\'s built for Android.\\n\\nI simply replaced `.toString()` by a call to `toBase(...)` and the app became fast on my phone too!\\n\\n:::note\\nThere is also a call to `.toString(16)` on the same number, but this one is very quick. The algorithm for base 16 must be much faster because it just has to split every byte into two hexadecimal values. So I didn\'t have to change this one.\\n:::\\n\\n## Future\\n\\nThere is [a TC39 proposal](https://github.com/tc39/proposal-number-fromstring) to give `BigInt` more capabilities, but as of 2023, it doesn\'t look like it\'s getting much traction."},{"id":"typesafe-translations","metadata":{"permalink":"/blog/typesafe-translations","editUrl":"https://github.com/zwyx/zwyx.dev/tree/master/blog/2023-09-19-typesafe-translations/index.mdx","source":"@site/blog/2023-09-19-typesafe-translations/index.mdx","title":"Type-safe translations with TypeScript and i18next","description":"Use TypeScript to ensure the validity of your i18next translations.","date":"2023-09-19T00:00:00.000Z","tags":[{"inline":true,"label":"i18n","permalink":"/blog/tags/i-18-n"},{"inline":true,"label":"i18next","permalink":"/blog/tags/i-18-next"},{"inline":true,"label":"vite","permalink":"/blog/tags/vite"},{"inline":true,"label":"typescript","permalink":"/blog/tags/typescript"},{"inline":true,"label":"react","permalink":"/blog/tags/react"},{"inline":true,"label":"tailwind","permalink":"/blog/tags/tailwind"},{"inline":true,"label":"shadcnui","permalink":"/blog/tags/shadcnui"}],"readingTime":3.23,"hasTruncateMarker":true,"authors":[{"name":"Alex","title":"Web developer","email":"alex@zwyx.dev","url":"https://github.com/Zwyx","imageURL":"https://github.com/zwyx.png","key":"alex","page":null}],"frontMatter":{"slug":"typesafe-translations","title":"Type-safe translations with TypeScript and i18next","description":"Use TypeScript to ensure the validity of your i18next translations.","image":"./typesafe-translations.jpg","authors":["alex"],"tags":["i18n","i18next","vite","typescript","react","tailwind","shadcnui"]},"unlisted":false,"prevItem":{"title":"Base conversions with BIG numbers in JavaScript","permalink":"/blog/base-conversions-with-big-numbers-in-javascript"},"nextItem":{"title":"All you need for a proper dark theme","permalink":"/blog/proper-dark-theme"}},"content":"import { Image } from \\"@site/src/components/Image\\";\\nimport screenshot2 from \\"./2.jpg\\";\\nimport screenshot3 from \\"./3.jpg\\";\\nimport screenshot4 from \\"./4.jpg\\";\\nimport screenshot5 from \\"./5.jpg\\";\\nimport translations from \\"./typesafe-translations.jpg\\";\\n\\n<Image src={translations} alt=\\"Translations\\" />\\n\\nUse TypeScript to ensure the validity of your i18next translations.\\n\\n{/* truncate */}\\n\\n---\\n\\n:::info\\nA demo project is available at [github.com/zwyx/typesafe-translations](https://github.com/zwyx/typesafe-translations)\\n:::\\n\\nTranslating software with i18next is easy:\\n\\n- we replace hard-coded text, for instance `Hello`, by a function call with a key, `t(\\"hello\\")`,\\n- we create translation files containing the text for the key in different languages:\\n\\n```json title=\\"en.json\\"\\n{\\n\\t\\"hello\\": \\"Hello\\"\\n}\\n```\\n\\n```json title=\\"fr.json\\"\\n{\\n\\t\\"hello\\": \\"Bonjour\\"\\n}\\n```\\n\\nThe problem is that there is **no easy way of detecting issues in translations**. For instance, if we change the key from `hello` to `hi`, then we have to update all the translation files manually.\\n\\nMany utilities have been made to improve the situation, often requirering extra build steps. Recently however, **it has became very nice and easy with i18next and TypeScript**.\\n\\n:::note\\nThis example uses a classic React single-page application, with no Server-Side Rendering or Static Site Generation. If you plan to use SSR or SSG \u2014 for instance with Next.js \u2014 you will have a more complex setup to create, in order to prevent hydration errors.\\n:::\\n\\n## Make the main language the reference\\n\\nThe types will be set by the translation file of our main language. For us, it will be English. It will become the source of truth.\\n\\nAll other language files, as well as the code of the app, will be type checked against it.\\n\\nWe start by creating the English translation file, as a TypeScript file:\\n\\n```ts title=\\"en.ts\\"\\nexport const en = {\\n\\tapp: {\\n\\t\\thello: \\"Hello\\",\\n\\t},\\n};\\n```\\n\\nThen, we want to create a type derived from this file, that we\'ll use with the other languages.\\n\\nTo do this, we create a `DeepReplace` utility type. It creates an interface from an object, containing all the keys of this object, with all their types changed to `string`.\\n\\n```ts title=\\"utils.ts\\"\\n// https://stackoverflow.com/questions/60437172/typescript-deep-replace-multiple-types\\ntype Replacement<M extends [unknown, unknown], T> = M extends unknown\\n\\t? [T] extends [M[0]]\\n\\t\\t? M[1]\\n\\t\\t: never\\n\\t: never;\\nexport type DeepReplace<T, M extends [unknown, unknown]> = {\\n\\t[P in keyof T]: T[P] extends M[0]\\n\\t\\t? Replacement<M, T[P]>\\n\\t\\t: T[P] extends object\\n\\t\\t  ? DeepReplace<T[P], M>\\n\\t\\t  : T[P];\\n};\\n```\\n\\nTo create our `I18nLocale` type, we use `DeepReplace` with the `en` object. The English translation file becomes:\\n\\n```ts title=\\"en.ts\\"\\nimport { DeepReplace } from \\"~/lib/utils\\";\\n\\nexport const en = {\\n\\tapp: {\\n\\t\\thello: \\"Hello\\",\\n\\t},\\n};\\n\\nexport type I18nLocale = DeepReplace<typeof en, [string, string]>;\\n```\\n\\n## Make the other languages follow the types of the main one\\n\\nWe want to use our `I18nLocale` in all other translation files:\\n\\n```ts title=\\"fr.ts\\"\\nimport { I18nLocale } from \\"./en\\";\\n\\nexport const fr: I18nLocale = {\\n\\tapp: {\\n\\t\\thello: \\"Bonjour\\",\\n\\t},\\n};\\n```\\n\\nOur translation files are now typed. A typo, or a missing key, is detected immediately:\\n\\n<Image src={screenshot2} alt=\\"Typo in translation file\\" />\\n\\nWe also now have intellisense available in the translation files:\\n\\n<Image src={screenshot4} alt=\\"Intellisense in translation file\\" />\\n\\n## Use the types in the code\\n\\nIn order to let i18next know about our types, we first create a `resources` constant containing all our languages, in the i18next initialisation file:\\n\\n```ts title=\\"i18n.ts\\"\\nimport { en } from \\"./locales/en\\";\\nimport { fr } from \\"./locales/fr\\";\\n\\nexport const resources = {\\n\\ten,\\n\\tfr,\\n};\\n```\\n\\nWe then create the file `src/@types/i18next.d.ts` \u2013 the path is important \u2013 containing:\\n\\n```ts title=\\"src/@types/i18next.d.ts\\"\\nimport { resources } from \\"@/i18n/i18n\\";\\n\\ndeclare module \\"i18next\\" {\\n\\tinterface CustomTypeOptions {\\n\\t\\tresources: (typeof resources)[\\"en\\"];\\n\\t}\\n}\\n```\\n\\nAnd that\'s it! Now our types are checked in the code:\\n\\n<Image src={screenshot3} alt=\\"Intellisense in translation file\\" />\\n\\nAnd we have Intellisense:\\n\\n<Image src={screenshot5} alt=\\"Intellisense in translation file\\" />\\n\\nFor more details on the implementation, check out the demo project at [github.com/zwyx/typesafe-translations](https://github.com/zwyx/typesafe-translations)."},{"id":"proper-dark-theme","metadata":{"permalink":"/blog/proper-dark-theme","editUrl":"https://github.com/zwyx/zwyx.dev/tree/master/blog/2023-09-12-proper-dark-theme/index.mdx","source":"@site/blog/2023-09-12-proper-dark-theme/index.mdx","title":"All you need for a proper dark theme","description":"Three states, no flash, reactive.","date":"2023-09-12T00:00:00.000Z","tags":[{"inline":true,"label":"dark theme","permalink":"/blog/tags/dark-theme"},{"inline":true,"label":"vite","permalink":"/blog/tags/vite"},{"inline":true,"label":"typescript","permalink":"/blog/tags/typescript"},{"inline":true,"label":"react","permalink":"/blog/tags/react"},{"inline":true,"label":"tailwind","permalink":"/blog/tags/tailwind"},{"inline":true,"label":"shadcnui","permalink":"/blog/tags/shadcnui"}],"readingTime":4.46,"hasTruncateMarker":true,"authors":[{"name":"Alex","title":"Web developer","email":"alex@zwyx.dev","url":"https://github.com/Zwyx","imageURL":"https://github.com/zwyx.png","key":"alex","page":null}],"frontMatter":{"slug":"proper-dark-theme","title":"All you need for a proper dark theme","description":"Three states, no flash, reactive.","image":"./dark-theme.webp","authors":["alex"],"tags":["dark theme","vite","typescript","react","tailwind","shadcnui"]},"unlisted":false,"prevItem":{"title":"Type-safe translations with TypeScript and i18next","permalink":"/blog/typesafe-translations"},"nextItem":{"title":"Your dotfiles in a Git repo","permalink":"/blog/your-dotfiles-in-a-git-repo"}},"content":"import { Image } from \\"@site/src/components/Image\\";\\nimport darkTheme from \\"./dark-theme.webp\\";\\n\\n<Image src={darkTheme} alt=\\"Translations\\" />\\n\\nThree states, no flash, reactive. Test it at [zwyx.github.io/proper-dark-theme](https://zwyx.github.io/proper-dark-theme)\\n\\n{/* truncate */}\\n\\n---\\n\\nAlthough implementing dark theme manually might sound like reinventing the wheel, it\'s actually easy and there are good reasons to do it:\\n\\n- dark theme libraries depend on a specific stack,\\n- UI/component libraries often \u2014 _incredibly often_, based on the dozen I\'ve tested \u2014 don\'t correctly implement the following requirements.\\n\\n## Three requirements for a proper dark theme\\n\\n### Three states\\n\\nThe user must be able to choose `same as device` (which should be the default), `light`, or `dark`.\\n\\n### No flash\\n\\nIf the current theme is dark, the page must not display a white background while it loads (very annoying at night, and possibly problematic for users with vision disabilities).\\n\\n### Reactive\\n\\nChanging the theme \u2014 including the device\'s theme, when `same as device` is selected \u2014 should be instantly effective on the page, without requiring to refresh it.\\n\\n:::tip\\nIn order to have these features, and not being dependent on a specific stack, I found that the best it to implement dark theme manually.\\n\\nOnce we know how to do it, we can reuse it everywhere. Instead of installing it as a library, we copy and paste it. We \xab own the code \xbb, which is a philosophy I first discovered with [Shadcn UI](https://ui.shadcn.com/docs).\\n:::\\n\\n## Implementation\\n\\nOur way of doing it will be:\\n\\n- have JavaScript applying a class `light` or `dark` to the root HTML element, and\\n- have different CSS variables depending on this class.\\n\\n:::info\\nA demonstration of this implementation is deployed [here](https://zwyx.github.io/proper-dark-theme/), and its code is present [here](https://github.com/zwyx/proper-dark-theme).\\n:::\\n\\n### The CSS\\n\\nCSS variables make it easy to have our app reactive: changing the class on the root HTML element instantly change all the color in the website, no refresh necessary.\\n\\n```css\\n:root {\\n\\t/* variables for light theme */\\n\\t--background: 0 0% 100%;\\n\\t--foreground: 222.2 84% 4.9%;\\n}\\n\\n:root.dark {\\n\\t/* variables for dark theme */\\n\\t--background: 222.2 84% 4.9%;\\n\\t--foreground: 210 40% 98%;\\n}\\n```\\n\\n### The HTML\\n\\nTo prevent the flash, we want to apply the `light` or `dark` class as soon as possible. This is what this small block of JavaScript, to be placed in the `head` of our HTML, does:\\n\\n```html\\n<meta name=\\"theme-color\\" content=\\"#020817\\" />\\n\\n<script>\\n\\t// Set the theme\'s class as soon as possible to prevent a flash of the wrong theme\\n\\n\\tvar lightThemeName = \\"light\\";\\n\\tvar darkThemeName = \\"dark\\";\\n\\tvar storedTheme = localStorage.getItem(\\"theme\\");\\n\\tvar theme;\\n\\n\\tif (storedTheme === lightThemeName || storedTheme === darkThemeName) {\\n\\t\\ttheme = storedTheme;\\n\\t} else if (matchMedia(\\"(prefers-color-scheme: dark)\\").matches) {\\n\\t\\ttheme = darkThemeName;\\n\\t} else {\\n\\t\\ttheme = lightThemeName;\\n\\t}\\n\\n\\tdocument.documentElement.classList.add(theme);\\n\\n\\tif (theme === lightThemeName) {\\n\\t\\tdocument\\n\\t\\t\\t.querySelector(\'meta[name=\\"theme-color\\"]\')\\n\\t\\t\\t?.setAttribute(\\"content\\", \\"#ffffff\\");\\n\\t}\\n<\/script>\\n```\\n\\nThe `theme-color` meta tag is optional, it\'s useful mainly if our app is a PWA. When using it, we want to keep it in sync with our theme color.\\n\\n### The JS\\n\\nThe JS has to maintain two state variables:\\n\\n- the user preference: `light`, `dark`, or `same as devices`\\n- the currently displayed theme:\\n  - `light`, when:\\n    - the user preference is `light`\\n    - the user preference is `same as device` and the device\'s theme is light\\n  - `dark`, when:\\n    - the user preference is `dark`\\n    - the user preference is `same as device` and the device\'s theme is dark\\n\\nTo do that, the JS has to:\\n\\n- react to changes of the user\'s theme preference,\\n- store it in local storage,\\n- listen for changes of the system\'s theme, which is done by adding an event listener to a media query:\\n\\n```ts\\nmatchMedia(\\"(prefers-color-scheme: dark)\\")\\n\\t.addEventListener(\\"change\\", ()=>{ ... });\\n```\\n\\n- update the HTML root element\'s class according to the user preference and the system\'s theme.\\n\\nI won\'t include the rest of the code here, instead I invite you to have a look at the [implementation made with TypeScript and React](https://github.com/Zwyx/proper-dark-theme/blob/main/src/lib/ThemeContext.tsx) for the demo project.\\n\\n## Sidenote\\n\\nI consider this three-state implementation to be the best at the moment, but I hope that it won\'t be necessary in the future.\\n\\nWhen all operating systems and all web browsers will implement dark theme seamlessly, then offering to the user the possibility to change the theme for a particular website might start to be seen as unnecessary. At least, the setting could be buried in a dialog box instead of being directly available on the top right of the page.\\n\\n## Bonus: with less JavaScript\\n\\nHere\'s another way of defining the CSS variables, which greatly reduces the amount of JS required. We use a media query to apply the dark theme when it\'s the system preference and the user hasn\'t selected the light theme.\\n\\n```css\\n:root {\\n\\t/* variables for light theme */\\n\\t--background: 0 0% 100%;\\n\\t--foreground: 222.2 84% 4.9%;\\n}\\n\\n:root.dark {\\n\\t/* variables for dark theme */\\n\\t--background: 222.2 84% 4.9%;\\n\\t--foreground: 210 40% 98%;\\n}\\n\\n@media only screen and (prefers-color-scheme: dark) {\\n\\t:root:not(.light) {\\n\\t\\t/* variables for dark theme */\\n\\t\\t--background: 222.2 84% 4.9%;\\n\\t\\t--foreground: 210 40% 98%;\\n\\t}\\n}\\n```\\n\\nBy doing that, the JS doesn\'t have to listen for changes of the system\'s theme anymore.\\n\\nThis is how I used to do it. However, it has a few drawbacks:\\n\\n- we have to duplicate the declaration of the dark theme\'s variables,\\n- the app cannot know which theme is currently displayed when the user preference is `same as device` (Tailwind\'s `dark:` selector, for instance, doesn\'t work)."},{"id":"your-dotfiles-in-a-git-repo","metadata":{"permalink":"/blog/your-dotfiles-in-a-git-repo","editUrl":"https://github.com/zwyx/zwyx.dev/tree/master/blog/2023-04-02-your-dotfiles-in-a-git-repo/index.mdx","source":"@site/blog/2023-04-02-your-dotfiles-in-a-git-repo/index.mdx","title":"Your dotfiles in a Git repo","description":"Track changes to your config files using a Git repository.","date":"2023-04-02T00:00:00.000Z","tags":[{"inline":true,"label":"dotfiles","permalink":"/blog/tags/dotfiles"},{"inline":true,"label":"git","permalink":"/blog/tags/git"}],"readingTime":6.71,"hasTruncateMarker":true,"authors":[{"name":"Alex","title":"Web developer","email":"alex@zwyx.dev","url":"https://github.com/Zwyx","imageURL":"https://github.com/zwyx.png","key":"alex","page":null}],"frontMatter":{"slug":"your-dotfiles-in-a-git-repo","title":"Your dotfiles in a Git repo","description":"Track changes to your config files using a Git repository.","image":"./gears-unsplash-xRDuEeG1TVI.webp","authors":["alex"],"tags":["dotfiles","git"]},"unlisted":false,"prevItem":{"title":"All you need for a proper dark theme","permalink":"/blog/proper-dark-theme"},"nextItem":{"title":"Consolidate your contribution graph","permalink":"/blog/own-contribution-graph"}},"content":"import { Image } from \\"@site/src/components/Image\\";\\nimport gears from \\"./gears-unsplash-xRDuEeG1TVI.webp\\";\\n\\n<Image src={gears} alt=\\"Gears\\" />\\n\\nTrack changes in your config files using a Git repository.\\n\\n{/* truncate */}\\n\\n---\\n\\n## Dotfiles\\n\\n_Dotfiles_ is the name given to the tiny text files containing the configuration for a piece of software. They\'re often placed in the your home directory and start with a dot to be hidable. We\'ll not limit ourselves to strictly dotfiles in this article though, what we\'ll do apply to any configuration file.\\n\\nBacking up these files and track changes to them is a good idea. It will be useful if you have to reinstall your system or set up a new machine, and, probably more often, you can restore your configuration if the corresponding software blows a gasket. It can happened with VS Code and its feature \\"Settings Sync\\" for instance: I was using VS Code on my machine and on [GitHub.dev](https://github.dev/), and settings got messed up. Thanks to the fact that my VS Code\'s config is tracked in Git, I just had to discard the current changes to have my config back.\\n\\n## Using Git to track them\\n\\nGit is the first choice to track changes in text files. However, all these config are in different places on the file system.\\n\\nSo how to gather them in one Git repository? There are a few methods:\\n\\n### 1. Create hard links or symlinks\\n\\nThis method is a pain: creating all the links is cumbersome. Also, some software delete and recreate their configuration files instead of modifying them, which breaks the links without us noticing it.\\n\\n### 2. Make your home directory the root of your Git config repository, and add only the files you want to track\\n\\nThis isn\'t recommended if you have other Git repositories anywhere in your home directory, as there would be a risk of interference.\\n\\n### 3. Use a bare Git repository and set its worktree to your home directory\\n\\nThe idea is to create a bare repository \u2014 which is simply a Git repository without a work tree \u2014 and then set its worktree to your home directory.\\n\\n> _How is this different from method 2?_\\n>\\n> Nothing shows that the home folder is the root of a repo. `git`, run in your home folder, will not see it as a repository, so has no risk of interfering with other repos present in your home folder.\\n\\n> _If we set the worktree of the bare repository... then it\'s not bare anymore!_\\n>\\n> Indeed. This method is known as the \\"bare repo method\\", but it might just be in order to avoid confusion with method 2. We actually don\'t need a bare repo, we just need to change the location of a repo\'s worktree. Don\'t be confused by this, or worried that it\'s too complex.\\n\\nThis article is about setting up this method.\\n\\n:::info\\nIf you\'re not keen to set this up yourself, or would like to have advanced features, have a look at existing dotfile managers. There are [plenty](https://dotfiles.github.io/utilities/), and [chezmoi](https://www.chezmoi.io/) seems to have become a reference in recent years.\\n:::\\n\\n## Setup\\n\\n:::caution\\nPlease read carefully and only execute commands that you fully understand. Wrong Git commands executed anywhere in your home directory could lead to a loss of data.\\n:::\\n\\nStart by creating a bare repository:\\n\\n```bash\\ngit init --bare ~/my-config\\n```\\n\\nThe folder `~/my-config` now contains the config repository. Now we want to set its worktree to be the home directory (replace `<your-name>` in the block below):\\n\\n```bash\\ncd ~/my-config\\ngit config --unset core.bare\\ngit config core.worktree \'/home/<your-name>\'\\ngit config status.showUntrackedFiles no\\n```\\n\\nThe file `~/my-config/config` should look like this:\\n\\n```ini\\n[core]\\n\\trepositoryformatversion = 0\\n\\tfilemode = true\\n\\tworktree = /home/<your-name>\\n[status]\\n\\tshowUntrackedFiles = no\\n```\\n\\nLet\'s add two functions in your `.zshrc` (or equivalent) to easily add and untrack config files:\\n\\n```bash\\n# We use functions instead of aliases to have folder and file name completion\\nconfig-add() {\\n\\tgit --git-dir=\\"$HOME/repo/config/.git-bare\\" add -f $@\\n}\\nconfig-untrack() {\\n\\tgit --git-dir=\\"$HOME/repo/config/.git-bare\\" rm --cached $@\\n}\\n```\\n\\n## Usage\\n\\n### Adding files to the config\\n\\n```bash\\nconfig-add .zshrc\\n```\\n\\n### Untrack files from the config\\n\\n```bash\\nconfig-untrack .zshrc\\n```\\n\\n### Commit, push, etc.\\n\\n:::danger\\nExecute regular git commands in your config repository \u2014 `git add`, `git commit`, `git push`, etc. **HOWEVER**, be very careful: commands like `git clean` could delete every untracked files from the home directory!\\n:::\\n\\nThat\'s it. Your config files are tracked in a git repo. Keep reading for a few more tips.\\n\\n### Set up a Cron task\\n\\nYou can create a cron job that commits and pushes your config once a week:\\n\\n- create a script containing:\\n\\n```bash\\ncd \\"$HOME/my-config\\"\\ngit add -A\\ngit commit -a -m \\"Weekly commit\\"\\ngit push\\n```\\n\\n- run:\\n\\n```bash\\ncrontab -e\\n```\\n\\n- and append:\\n\\n```\\n30 12 * * 5 <path-to-script>\\n```\\n\\nYou can also add other useful tasks in the script, just before the the three `git` commands. For instance:\\n\\n- `code --list-extensions > ~/.config/vscode-extensions.txt`\\n- `dconf dump / > ~/.config/dconf.ini`\\n- `crontab -l > ~/.config/crontab.txt`\\n\\n## Special cases\\n\\n### Tracking files from other Git repositories\\n\\nAdding files that are already present in another Git repository seems to be impossible.\\n\\nFor instance, I didn\'t find a way to add `~/.nvm/default-packages`, because `~/.nvm` is a Git repository.\\n\\nSo for this kind of file, I use the hard link method:\\n\\n```bash\\nln `~/.nvm/default-packages` `~/my-config/default-packages`\\n```\\n\\n### Sublime Merge users\\n\\nAt the moment, Sublime Merge [ignores the property `status.showUntrackedFiles`](https://github.com/sublimehq/sublime_merge/issues/1544) and will show all the untracked files of the home folder.\\n\\nTo prevent this, it is possible to add a `.gitignore` in the repo\'s root folder. This `.gitignore` mainly needs to contain a `*`, to hide all untracked files, although you can also \\"unhide\\" specific subfolders if you want your weekly commit to automatically includes new files from these folders.\\n\\nHere\'s an example:\\n\\n```txt showLineNumbers\\n/*\\n\\n!.gitignore\\n\\n!.config/Code\\n.config/Code/*\\n!.config/Code/User\\n.config/Code/User/*\\n!.config/Code/User/snippets\\n```\\n\\n- line 1: hide everything;\\n- line 3: unhide the file `.gitignore`;\\n- line 5: unhide the folder `.config/Code`...\\n- line 6: but hide everything inside this folder;\\n- line 7: unhide the folder `.config/Code/User`...\\n- line 8: but hide everything inside this folder;\\n- line 9: unhide the folder `.config/Code/User/snippets`, so all files in this folder will be tracked in our config.\\n\\n:::caution\\nThis `.gitignore` file has a side effect on `git checkout`. Indeed, usually, when cloning a repository and running `git checkout`, if some files in the worktree are different than the ones in the repository, git displays the message `error: The following untracked working tree files would be overwritten by checkout: ...`. But with this `.gitignore` in the home directory, `git checkout` will simply override the files that are in the home directory by the ones from the repository. Without warning!\\n\\nHowever, the point it to be able to use Sublime Merge, so we don\'t need `git checkout`. We simply open the repository in Sublime Merge, keep the files we want, and we discard the others.\\n:::\\n\\nSublime Merge has another bug when working with a repository whose work tree isn\'t next to the repo itself: [the corresponding tab isn\'t reopen correctly](https://github.com/sublimehq/sublime_merge/issues/1670). So, here\'s an alias to quickly open your config repo in Sublime Merge:\\n\\n```bash\\nalias config-open-in-sublime-merge=\'\\"$HOME/.config/open-in-sublime-merge.sh\\" \\"$HOME/my-config\\"\'\\n```\\n\\n```bash title=\\"open-in-sublime-merge.sh\\"\\n#!/bin/bash\\n\\nif pgrep sublime_merge; then\\n\\tif [[ -d $1 ]]; then\\n\\t\\t/opt/sublime_merge/sublime_merge \\"$1\\"\\n\\telse\\n\\t\\t/opt/sublime_merge/sublime_merge \\"$(dirname \\"$1\\")\\"\\n\\tfi\\nelse\\n\\txmessage \\"Start Sublime Merge before to prevent losing all open tabs.\\"\\nfi\\n```\\n\\nAs you can see, we check that `sublime_merge` is already running before attempting to open the repository. This is because of [yet another bug in Sublime Merge](https://github.com/sublimehq/sublime_merge/issues/309) (at this point you might be wondering why I use this tool... I swear it\'s a great tool, altough it\'s definitely frustrating to be paying for a licence and barely receive any reply to the bug reports I create)."},{"id":"own-contribution-graph","metadata":{"permalink":"/blog/own-contribution-graph","editUrl":"https://github.com/zwyx/zwyx.dev/tree/master/blog/2023-03-31-own-contribution-graph/index.mdx","source":"@site/blog/2023-03-31-own-contribution-graph/index.mdx","title":"Consolidate your contribution graph","description":"Combine your contributions from any repository on your GitHub contribution graph.","date":"2023-03-31T00:00:00.000Z","tags":[{"inline":true,"label":"git","permalink":"/blog/tags/git"}],"readingTime":2.03,"hasTruncateMarker":true,"authors":[{"name":"Alex","title":"Web developer","email":"alex@zwyx.dev","url":"https://github.com/Zwyx","imageURL":"https://github.com/zwyx.png","key":"alex","page":null}],"frontMatter":{"slug":"own-contribution-graph","title":"Consolidate your contribution graph","description":"Combine your contributions from any repository on your GitHub contribution graph.","image":"./skyline-zwyx-2021.webp","authors":["alex"],"tags":["git"]},"unlisted":false,"prevItem":{"title":"Your dotfiles in a Git repo","permalink":"/blog/your-dotfiles-in-a-git-repo"},"nextItem":{"title":"Indentation for accessibility","permalink":"/blog/indentation-for-accessibility"}},"content":"import { Image } from \\"@site/src/components/Image\\";\\nimport contributionGraph from \\"./contribution-graph-rotated--5deg.webp\\";\\nimport skylineZwyx2021Printed from \\"./skyline-zwyx-2021-printed.webp\\";\\nimport skylineZwyx2021 from \\"./skyline-zwyx-2021.webp\\";\\n\\n<Image src={skylineZwyx2021} legend=\\"GitHub Skyline\\" />\\n\\nCombine your contributions from any repository on your GitHub contribution graph.\\n\\n{/* truncate */}\\n\\n---\\n\\n## The GitHub contribution graph\\n\\nA friend and I used to work at the same company, where we were using GitHub.\\n\\nEvery year, our contribution graphs looked nice and it was kinda rewarding.\\n\\n<Image src={contributionGraph} legend=\\"A contribution graph on GitHub\\" />\\n\\nYou can do more than just look at it on your GitHub profile page: [GitHub Skyline](https://skyline.github.com/) lets you generate a 3D version of it\xa0\u2014\xa0which is the image at the top of this article. You can then download the 3D file and print it:\\n\\n<Image src={skylineZwyx2021Printed} legend=\\"Code trophy!\\" />\\n\\n## Not on GitHub anymore?\\n\\nThe companies we work for now however, use other Git hosting providers. Which means... no more contribution graphs on GitHub \ud83d\ude22\\n\\nThis is where Tim had a beautiful idea: create a tool that regularly scans our work repositories, and creates empty commits in a repository hosted on GitHub! Each empty commit corresponds to a commit made by ourselves in our work repositories, and is made with the same commit date.\\n\\nThe repository gathering all these empty commits can be private on GitHub. (Although even if it\'s public, no content is present in it.)\\n\\nBrilliant!\\n\\n## Usage\\n\\nThe tool is [own-contribution-graph](https://npmjs.com/package/own-contribution-graph). To use it, simply:\\n\\n- install the package:\\n\\n```bash\\nnpm i -g own-contribution-graph\\n```\\n\\n- create the configuration file following the instructions in the [ReadMe](https://npmjs.com/package/own-contribution-graph),\\n\\n- run the following command:\\n\\n```bash\\nowncontributiongraph --config=<path-to-the-json-config-file>\\n```\\n\\n:::tip\\n\\n- I added `own-contribution-graph` to the file `~/.nvm/default-packages`, so [nvm](https://github.com/nvm-sh/nvm) automatically installs it when I install a new version of Node.\\n- I created a Cron task that executes this command every week, and push to a private GitHub repository.\\n\\n:::\\n\\nOur contributions graphs are alive again!\\n\\nThere is a difference though: the merge method we used to use was _rebase merging_, where all commits from a feature branch are applied one by one on the main branch. Now we use _squash merging_, were all commits are squashed together into one commit that is applied on the main branch. So less contributions appear on the graph."},{"id":"indentation-for-accessibility","metadata":{"permalink":"/blog/indentation-for-accessibility","editUrl":"https://github.com/zwyx/zwyx.dev/tree/master/blog/2023-01-05-indentation-for-accessibility/index.mdx","source":"@site/blog/2023-01-05-indentation-for-accessibility/index.mdx","title":"Indentation for accessibility","description":"The real reason to use tabs over spaces","date":"2023-01-05T00:00:00.000Z","tags":[{"inline":true,"label":"code","permalink":"/blog/tags/code"},{"inline":true,"label":"indentation","permalink":"/blog/tags/indentation"},{"inline":true,"label":"formatter","permalink":"/blog/tags/formatter"},{"inline":true,"label":"prettier","permalink":"/blog/tags/prettier"}],"readingTime":2.7,"hasTruncateMarker":true,"authors":[{"name":"Alex","title":"Web developer","email":"alex@zwyx.dev","url":"https://github.com/Zwyx","imageURL":"https://github.com/zwyx.png","key":"alex","page":null}],"frontMatter":{"slug":"indentation-for-accessibility","title":"Indentation for accessibility","description":"The real reason to use tabs over spaces","authors":["alex"],"tags":["code","indentation","formatter","prettier"]},"unlisted":false,"prevItem":{"title":"Consolidate your contribution graph","permalink":"/blog/own-contribution-graph"},"nextItem":{"title":"Hello Docusaurus!","permalink":"/blog/hello-docusaurus"}},"content":"It\'s quite obvious, for consistently looking code, spaces are best.\\n\\nHowever, does one also has consistency among the people they work with?\\n\\nIt might not be the case: some people might have impaired vision.\\n\\nOn an open source project, one might not even know how \\"consistent\\" are the people working with them.\\n\\n{/* truncate */}\\n\\nSome require such big font sizes, that [being able to set the tab width to 1 is a big deal](https://www.reddit.com/r/javascript/comments/c8drjo/nobody_talks_about_the_real_reason_to_use_tabs/). (I am short-sighted, and although I don\'t have special needs other than wearing glasses, I can understand how useful it can be for others).\\n\\nAfter working years on projects using spaces, and years on projects using tabs, what\'s apparent to me is that **for most developers, tabs or spaces don\'t change anything**. We adapt easily to one choice or the other.\\n\\n**The only persons for whom it matters, are people with special needs. And for them, tabs are better.** Shouldn\'t this be a done deal?\\n\\nThis is even more true these days, as many languages now have great tools to autoformat our code. If an autoformatter is available for a language, then using it should be a priority. It is SO great to not have ever to think about indentation or formatting.\\n\\n---\\n\\nWith tabs, the code will not consistently look the same on everyone\'s screen anymore, but another thing will become consistent: **a good experience for everyone**.\\n\\n**This is for this exact reason that the web has introduced media queries** like [`prefers-color-scheme`](https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme) and [`prefers-contrast`](https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-contrast). We want to improve accessibility of websites; source codes deserve the same.\\n\\n---\\n\\nSo, my recommendations is to set the project settings to fix the differences between operating systems that developers shouldn\'t have to deal with, and set some preferences like trimming trailing whitespaces.\\n\\nThat\'s it. Do not set the tab width, it is a user setting.\\n\\nForcing the tab width would be like forcing a bright high contrast theme for everyone in the project.\\n\\n---\\n\\nSo for example, here\'s an [`.editorconfig`](https://editorconfig.org) file:\\n\\n```ini\\n# https://editorconfig.org\\n\\n[*]\\ncharset = utf-8\\nend_of_line = lf\\nindent_style = \\"tab\\"\\ntrim_trailing_whitespace = true\\ninsert_final_newline = true\\n```\\n\\nAnd a `.vscode/settings.json` file:\\n\\n```json\\n{\\n\\t\\"files.encoding\\": \\"utf8\\",\\n\\t\\"files.eol\\": \\"\\\\n\\",\\n\\t\\"files.trimTrailingWhitespace\\": true,\\n\\t\\"files.insertFinalNewline\\": true,\\n\\t\\"files.trimFinalNewlines\\": true,\\n\\t\\"editor.insertSpaces\\": false,\\n\\t\\"editor.defaultFormatter\\": \\"esbenp.prettier-vscode\\"\\n}\\n```\\n\\n---\\n\\n(We sometimes read that developers who use spaces make more money. Does it sound like BS? It probably is. Developers using spaces could simply be paid more because they\'re older (so have old habits). Young developers (paid less) could have answered that they use tabs because they press the Tab key when indenting. And there\'s more, see the comments below the [original post](https://stackoverflow.blog/2017/06/15/developers-use-spaces-make-money-use-tabs/).)\\n\\n---\\n\\n**TL;DR: I recommend to use tabs and to not force their width (and to use an automatic formatter for everything else if possible).** Of cours, this doesn\'t apply if the project/language you work with doesn\'t allow it for technical reasons.\\n\\n---\\n\\n_This post was originally my answer to this [StackOverflow question](https://stackoverflow.com/questions/35649847/objective-reasons-for-using-spaces-instead-of-tabs-for-indentation/75019495#75019495)._"},{"id":"hello-docusaurus","metadata":{"permalink":"/blog/hello-docusaurus","editUrl":"https://github.com/zwyx/zwyx.dev/tree/master/blog/2022-11-22-hello-docusaurus/index.mdx","source":"@site/blog/2022-11-22-hello-docusaurus/index.mdx","title":"Hello Docusaurus!","description":"A few tips on how I built this site with the great static site generator Docusaurus","date":"2022-11-22T00:00:00.000Z","tags":[{"inline":true,"label":"docusaurus","permalink":"/blog/tags/docusaurus"},{"inline":true,"label":"static site generator","permalink":"/blog/tags/static-site-generator"},{"inline":true,"label":"blog","permalink":"/blog/tags/blog"}],"readingTime":5.55,"hasTruncateMarker":true,"authors":[{"name":"Alex","title":"Web developer","email":"alex@zwyx.dev","url":"https://github.com/Zwyx","imageURL":"https://github.com/zwyx.png","key":"alex","page":null}],"frontMatter":{"slug":"hello-docusaurus","title":"Hello Docusaurus!","description":"A few tips on how I built this site with the great static site generator Docusaurus","image":"./docusaurus.svg","authors":["alex"],"tags":["docusaurus","static site generator","blog"]},"unlisted":false,"prevItem":{"title":"Indentation for accessibility","permalink":"/blog/indentation-for-accessibility"},"nextItem":{"title":"Git Hash Miner: mine your commit hashes!","permalink":"/blog/git-hash-miner"}},"content":"<div style={{ textAlign: \\"center\\" }}>\\n\\n![Docusaurus](docusaurus.svg)\\n\\n</div>\\n\\nI\'ve investigated different static site generators \u2014 SSGs \u2014 in order to set up a proper blog for this website. I\'ve read about a lot of them, tried a few. My favourite by far is [Docusaurus](https://docusaurus.io), the one this site is now built with.\\n\\n{/* truncate */}\\n\\n## Quick comparison\\n\\nAs I\'m working on complex web apps during the day, SSGs make evening projects feel like holiday.\\n\\nStill, I found that many of them require quite some tinkering before achieving desired results. In theory, to have a quick website set up, we can start from a template. But unfortunately this is where most of the pain come from. Many templates I looked at where incomplete, old, unmaintained, or simply ugly.\\n\\nDocusaurus is the one which has the best of both:\\n\\n- A great template to start with.\\n\\nThere is [only one](https://docusaurus.io/docs/api/themes) at the moment. It has basically everything I wanted and it\'s very nice. So it\'s much better than a choice of 100 useless templates. It might be a bit of a problem for someone really not liking it... but still, wait for the next point.\\n\\n- A great way to tinker and customise it.\\n\\nDocusaurus provides multiple ways to customise the [styling and layout](https://docusaurus.io/docs/styling-layout), depending on what we want to change, and how deep we want to change it. From creating React components and use them in [MDX](https://mdxjs.com/), to the brilliant [swizzling](https://docusaurus.io/docs/swizzling) method allowing to easily cherry pick a component to wrap it or replace it (there is an example in the [Add comment system](#add-comment-system) section below).\\n\\n## Setup\\n\\n:::note\\nI will write about the choices I\'ve made during the building of this blog. I won\'t detail every steps\xa0\u2014\xa0official docs are better sources and will stay up to date.\\n:::\\n\\n### Create a new Docusaurus project\\n\\n```bash\\nnpx create-docusaurus@latest your-project-name classic --typescript\\n```\\n\\nThis is all what\'s needed to have a complete website with dummy pages ready to be filled with content.\\n\\n:::tip\\nIf you\'re sick of having a new browser tab being opened every time you run the `start` command, append `--no-open`.\\n:::\\n\\n### Setup Prettier\\n\\n[Prettier](https://prettier.io/) formats Markdown well, it will be appreciated while writing blog posts.\\n\\n### Set up redirect to `/blog`\\n\\nI wanted the blog to be the only content of the site for the moment. But I didn\'t want to [make the blog base URL simply `/`](https://docusaurus.io/docs/blog#blog-only-mode), as all the post links would be in the format `<domain>/<post>`, which could potentially become annoying if I wanted to add other types of content to the site in the future.\\n\\nSo I kept the blog base URL `/blog` (post links are `<domain>/blog/<post>`), and I created a redirect from `/` to `/blog`.\\n\\n:::info\\nServer-side redirects are best, but as I\'m hosting the site on GitHub Pages, this isn\'t an option.\\n:::\\n\\nDocusaurus provides a [plugin for client-side redirects](https://docusaurus.io/docs/next/api/plugins/@docusaurus/plugin-client-redirects):\\n\\n```bash\\nnpm i @docusaurus/plugin-client-redirects\\n```\\n\\n```js title=\\"Extract from \'docusaurus.config.js\'\\"\\nplugins: [\\n\\t[\\n\\t\\t\\"@docusaurus/plugin-client-redirects\\",\\n\\t\\t/** @type {import(\'@docusaurus/plugin-client-redirects\').Options} */\\n\\t\\t({\\n\\t\\t\\tredirects: [\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\tfrom: \\"/\\",\\n\\t\\t\\t\\t\\tto: \\"/blog\\",\\n\\t\\t\\t\\t},\\n\\t\\t\\t],\\n\\t\\t}),\\n\\t],\\n],\\n```\\n\\n### Deactivate `docs`\\n\\n```js title=\\"Extract from \'docusaurus.config.js\'\\"\\npresets: [\\n\\t[\\n\\t\\t\\"classic\\",\\n\\t\\t...\\n\\t\\t\\tdocs: false,\\n```\\n\\n### Add metadata\\n\\nAdding the following makes links to the blog look pretty when shared.\\n\\n```js title=\\"Extract from \'docusaurus.config.js\'\\"\\npresets: [\\n\\t[\\n\\t\\t\\"classic\\",\\n\\t\\t...\\n\\t\\t\\tblog: {\\n\\t\\t\\t\\tblogTitle: \\"<Blog title>\\",\\n\\t\\t\\t\\tblogDescription: \\"<Blog description>\\",\\n```\\n\\n```js title=\\"Extract from \'docusaurus.config.js\'\\"\\nthemeConfig:\\n\\t...\\n\\t\\timage: \\"<Image path>\\",\\n```\\n\\n### Activate all feed types\\n\\nJust because I want all the shiny new stuff, I activated all the [types of feeds](https://docusaurus.io/docs/next/blog#feed).\\n\\n```js title=\\"Extract from \'docusaurus.config.js\'\\"\\npresets: [\\n\\t[\\n\\t\\t\\"classic\\",\\n\\t\\t...\\n\\t\\t\\tblog: {\\n\\t\\t\\t\\tfeedOptions: {\\n\\t\\t\\t\\t\\ttype: \\"all\\",\\n\\t\\t\\t\\t\\ttitle: \\"<Blog title>\\", // By default, it\'s in the format `<Site name> Blog`\\n\\t\\t\\t\\t\\tdescription: \\"<Blog description>\\", // Same here\\n\\t\\t\\t\\t},\\n```\\n\\n### Add comment system\\n\\n[Giscus](https://giscus.app/) is a great comment system powered by GitHub Discussions.\\n\\nInstall its React component:\\n\\n```bash\\nnpm i @giscus/react\\n```\\n\\nUse [giscus.app](https://giscus.app) to set up and retrieve your configuration for Giscus, then create the file `src/components/GiscusComments.tsx`:\\n\\n```tsx title=\\"src/components/GiscusComments.tsx\\"\\nimport { useColorMode } from \\"@docusaurus/theme-common\\";\\nimport useDocusaurusContext from \\"@docusaurus/useDocusaurusContext\\";\\nimport Giscus from \\"@giscus/react\\";\\nimport React from \\"react\\";\\n\\nexport default function GiscusComments() {\\n\\tconst {\\n\\t\\tsiteConfig: {\\n\\t\\t\\tcustomFields: {\\n\\t\\t\\t\\tgiscusRepo,\\n\\t\\t\\t\\tgiscusRepoId,\\n\\t\\t\\t\\tgiscusCategory,\\n\\t\\t\\t\\tgiscusCategoryId,\\n\\t\\t\\t},\\n\\t\\t},\\n\\t} = useDocusaurusContext();\\n\\n\\tconst { colorMode } = useColorMode();\\n\\n\\tif (\\n\\t\\ttypeof giscusRepo !== \\"string\\" ||\\n\\t\\ttypeof giscusRepoId !== \\"string\\" ||\\n\\t\\ttypeof giscusCategory !== \\"string\\" ||\\n\\t\\ttypeof giscusCategoryId !== \\"string\\"\\n\\t) {\\n\\t\\treturn null;\\n\\t}\\n\\n\\treturn (\\n\\t\\t<Giscus\\n\\t\\t\\trepo={giscusRepo as `${string}/${string}`}\\n\\t\\t\\trepoId={giscusRepoId}\\n\\t\\t\\tcategory={giscusCategory}\\n\\t\\t\\tcategoryId={giscusCategoryId}\\n\\t\\t\\tmapping=\\"pathname\\"\\n\\t\\t\\tstrict=\\"0\\"\\n\\t\\t\\treactionsEnabled=\\"1\\"\\n\\t\\t\\temitMetadata=\\"0\\"\\n\\t\\t\\tinputPosition=\\"bottom\\"\\n\\t\\t\\ttheme={colorMode}\\n\\t\\t\\tlang=\\"en\\"\\n\\t\\t/>\\n\\t);\\n}\\n```\\n\\n:::tip\\nI used Docusaurus\' [custom fields](https://docusaurus.io/docs/next/api/docusaurus-config#customfields) to retrieve Giscus configuration from Docusaurus\' config (itself retrieving these values using [`dotenv`](https://www.npmjs.com/package/dotenv))\\n:::\\n\\nIn order to add the Giscus component to our blog posts, we are going to use Docusaurus\' swizzling method to wrap one component of the template (read about swizzling [here](https://docusaurus.io/docs/next/swizzling)):\\n\\n```bash\\nnpm run swizzle @docusaurus/theme-classic BlogPostItem --wrap\\n```\\n\\nThis command creates a new file:\\n\\n```\\nsrc/theme/BlogPostItem/index.js\\n```\\n\\nwhich we can directly rename to `.tsx`:\\n\\n```\\nsrc/theme/BlogPostItem/index.tsx\\n```\\n\\n:::info\\nNow we need to restart Docusaurus\' dev server, in order for it to take the new custom component into account.\\n:::\\n\\nThis file is a wrapper for the `BlogPostItem` component. We can very easily add our new `GiscusComments` component just below it:\\n\\n```tsx title=\\"src/theme/BlogPostItem/index.tsx\\"\\nimport useIsBrowser from \\"@docusaurus/useIsBrowser\\";\\nimport GiscusComments from \\"@site/src/components/GiscusComments\\";\\nimport BlogPostItem from \\"@theme-original/BlogPostItem\\";\\nimport React from \\"react\\";\\n\\nconst POST_REGEX = /^\\\\/blog\\\\/.+$/;\\n\\nexport default function BlogPostItemWrapper(props) {\\n\\tconst isBrowser = useIsBrowser();\\n\\n\\treturn (\\n\\t\\t<>\\n\\t\\t\\t<BlogPostItem {...props} />\\n\\n\\t\\t\\t{isBrowser && window.location.pathname.match(POST_REGEX) && (\\n\\t\\t\\t\\t<>\\n\\t\\t\\t\\t\\t<div style={{ marginTop: \\"32px\\" }} />\\n\\n\\t\\t\\t\\t\\t<GiscusComments />\\n\\n\\t\\t\\t\\t\\t<div style={{ marginTop: \\"-24px\\" }} />\\n\\t\\t\\t\\t</>\\n\\t\\t\\t)}\\n\\t\\t</>\\n\\t);\\n}\\n```\\n\\n:::tip[Details]\\n\\n- We check that the `pathname` matches `/blog/...` to not show the Giscus component below all the posts on the main listing page (`/blog`).\\n- `isBrowser` is to prevent evaluating `window` at build time, which would creates an error.\\n\\n:::\\n\\nLast thing, to be done once your local testing is finish, is to add a file `giscus.json` at the root of the repository to [prevent other websites from showing your discussions](https://github.com/giscus/giscus/blob/main/ADVANCED-USAGE.md#giscusjson):\\n\\n```json title=\\"giscus.json\\"\\n{\\n\\t\\"origins\\": [\\"https://<your-domain>\\"]\\n}\\n```\\n\\nGiscus will stop showing on your `localhost:3000` after this file is committed.\\n\\n### Automatically deploy to GitHub Pages, Netlify, etc.\\n\\nThe site is deployed on very push to the `main` branch. The [code](https://github.com/Zwyx/zwyx.dev/blob/main/.github/workflows/build-website.yml) should be self-explanatory with enough knowledge on [GitHub Actions](https://docs.github.com/en/actions) and [GitHub Pages](https://docs.github.com/en/pages)."},{"id":"git-hash-miner","metadata":{"permalink":"/blog/git-hash-miner","editUrl":"https://github.com/zwyx/zwyx.dev/tree/master/blog/2022-03-05-git-hash-miner/index.mdx","source":"@site/blog/2022-03-05-git-hash-miner/index.mdx","title":"Git Hash Miner: mine your commit hashes!","description":"Following the same principle that Bitcoin uses for its proof of work, we can \\"mine\\" our Git commit hashes too!","date":"2022-03-05T00:00:00.000Z","tags":[{"inline":true,"label":"git","permalink":"/blog/tags/git"},{"inline":true,"label":"commit","permalink":"/blog/tags/commit"},{"inline":true,"label":"hash","permalink":"/blog/tags/hash"}],"readingTime":3.23,"hasTruncateMarker":true,"authors":[{"name":"Alex","title":"Web developer","email":"alex@zwyx.dev","url":"https://github.com/Zwyx","imageURL":"https://github.com/zwyx.png","key":"alex","page":null}],"frontMatter":{"slug":"git-hash-miner","title":"Git Hash Miner: mine your commit hashes!","description":"Following the same principle that Bitcoin uses for its proof of work, we can \\"mine\\" our Git commit hashes too!","image":"./git-hash-miner.webp","authors":["alex"],"tags":["git","commit","hash"]},"unlisted":false,"prevItem":{"title":"Hello Docusaurus!","permalink":"/blog/hello-docusaurus"},"nextItem":{"title":"Google Authenticator export format","permalink":"/blog/google-authenticator-export-format"}},"content":"import { Image } from \\"@site/src/components/Image\\";\\nimport gitHashMiner from \\"./git-hash-miner.webp\\";\\nimport sublimeMerge from \\"./sublime-merge.webp\\";\\n\\n<Image src={gitHashMiner} legend=\\"Git hashes mined with Git Hash Miner\\" />\\n\\nFollowing the same principle that Bitcoin uses for its proof of work, we can \\"mine\\" our Git commit hashes too!\\n\\n{/* truncate */}\\n\\n---\\n\\n:::note[About hash mining]\\nTo be accepted in the Bitcoin blockchain, the numerical value of a block\'s hash needs to be lower than a certain number. This make the hash starting with some zeros. This number is regularly reduced, as computers get more powerful; the smaller the number, the harder it is to find a winning hash.\\n:::\\n\\nWe can do the same with Git commit hashes: mine them to make them start with a particular prefix. Or end with a particular suffix, or any other rule we\'d like.\\n\\n## How are Git commit hashes generated\\n\\nRoughly, when a commit is created, Git take these details:\\n\\n- the hash of the parent commit,\\n- the hash of the tree object,\\n- the author\'s name and email address,\\n- the commit creation date,\\n- the committer\'s name and email address,\\n- the committing date (which will different than the creation date after, for instance, an amend or a rebase),\\n- the PGP signature if the commit has been signed,\\n- the title and body of the commit,\\n\\nand generates a SHA-1 hash with them. That\'s the commit hash.\\n\\n:::tip\\nTo \\"mine\\" a commit hash, we need to generate multiple hashes until we find one that respects our rule (for instance, starts with a particular prefix). But to make each hash different than the previous one, we need to change something in the details listed above.\\n:::\\n\\nI made the package [`git-hash-miner`](https://npmjs.com/package/git-hash-miner), which appends a hexadecimal number to the committer name of the last commit, regenerates the SHA-1 hash of the commit details, and continues by incrementing the hexadecimal number at each round until a winning hash is found.\\n\\nOnce it is found, `git-hash-miner` can automatically amend the commit to add the hexadecimal number to the committer name, and let Git handle the commit and generate the SHA-1, which will be the winning one found just before.\\n\\nThe committer\'s name is usually not shown by git clients, so it\'s not an issue to have it modified.\\n\\nAnd even when it\'s shown, by Sublime Merge for instance, I believe it\'s not a big deal to have the committer\'s name followed by a bunch of hexadecimal digits:\\n\\n<Image\\n\\tsrc={sublimeMerge}\\n\\tlegend=\\"Hexadecimal number appended to the committer name\\"\\n/>\\n\\n## Mine your commit hashes!\\n\\n- Install `git-hash-miner`:\\n\\n```bash\\nnpm i -g git-hash-miner\\n```\\n\\n- Then, in a Git repository, run this command after having created a commit:\\n\\n```bash\\ngmr [--auto-amend|-a] <target>\\n```\\n\\nwhere `target` is the prefix we want the commit hash to start with, and `-a` automatically amends the commit if the target is found. Do some tests without `-a` first.\\n\\nExample: the command `gmr -a badc0de` will search for a commit hash starting with `badc0de` then automatically amend the previous commit once it\'s found.\\n\\n`git-hash-miner` creates a worker for each CPU core on your machine. Roughly, you should be able to mine a hash with a prefix of up to 6 or 7 characters in a few minutes.\\n\\n:::tip[Pro tip]\\nI added `git-hash-miner` to the file `~/.nvm/default-packages`, so [nvm](https://github.com/nvm-sh/nvm) automatically installs it when I install a new version of Node.\\n:::\\n\\n:::note\\nNote that there are other projects of this kind around the internet, some of them more performant as they use GPUs. They are, however, more complex to install than `git-hash-miner`, which is a simple Node script.\\n:::\\n\\n:::info\\nAlso note that at the moment, if you sign your commits, then your signature is dropped when using `git-hash-miner`.\\n:::\\n\\n---\\n\\nHave fun mining!"},{"id":"google-authenticator-export-format","metadata":{"permalink":"/blog/google-authenticator-export-format","editUrl":"https://github.com/zwyx/zwyx.dev/tree/master/blog/2021-11-25-google-authenticator-export-format/index.mdx","source":"@site/blog/2021-11-25-google-authenticator-export-format/index.mdx","title":"Google Authenticator export format","description":"How to rename the issuers of your Google Authenticator one-time passwords.","date":"2021-11-25T00:00:00.000Z","tags":[{"inline":true,"label":"google authenticator","permalink":"/blog/tags/google-authenticator"},{"inline":true,"label":"totp","permalink":"/blog/tags/totp"},{"inline":true,"label":"one time password","permalink":"/blog/tags/one-time-password"}],"readingTime":2.01,"hasTruncateMarker":true,"authors":[{"name":"Alex","title":"Web developer","email":"alex@zwyx.dev","url":"https://github.com/Zwyx","imageURL":"https://github.com/zwyx.png","key":"alex","page":null}],"frontMatter":{"slug":"google-authenticator-export-format","title":"Google Authenticator export format","description":"How to rename the issuers of your Google Authenticator one-time passwords.","authors":["alex"],"tags":["google authenticator","totp","one time password"]},"unlisted":false,"prevItem":{"title":"Git Hash Miner: mine your commit hashes!","permalink":"/blog/git-hash-miner"},"nextItem":{"title":"Tidy up a Git repo by archiving branches","permalink":"/blog/archiving-git-branches"}},"content":"If you use Google Authenticator and scan QR codes to create new Time-based One-Time Passwords, you might have noticed that their names are sometimes in the form `Issuer (Account name)`. Google Authenticator allows to rename the `Account name` part, but not the `Issuer`.\\n\\nThe following explains how to rename the `Issuer`, or even get rid of it.\\n\\n{/* truncate */}\\n\\n## Requirements\\n\\n- The Google Protocol Buffers tool, which can be found [here](https://developers.google.com/protocol-buffers), or in [this repository](https://github.com/Zwyx/google-authenticator-export-format).\\n\\n- The `OtpMigration.proto` file present [here](https://github.com/qistoph/otp_export/blob/master/OtpMigration.proto) \u2014 thank you to the author \u2014 or [here](https://github.com/Zwyx/google-authenticator-export-format).\\n\\n- A way to scan and create QR codes \u2014 `zbarcam` and `qrencode` for instance.\\n\\n## Export, edit, and import Google Authenticator\'s data\\n\\nIn Google Authenticator settings, export your accounts. The app will display a QR code containing your TOTP data encoded with Protocol Buffers and URL encoded base64. If you have lots of accounts, then multiple QR codes will be created.\\n\\nUse the next command with one QR code at a time.\\n\\nI use ZSH. You might have to tweak the commands if you use a different shell.\\n\\n```bash\\nzbarcam | \\\\\\n\\tsed \'s/QR-Code://\' | \\\\\\n\\tsed \'s/otpauth-migration:\\\\/\\\\/offline?data=//\' | \\\\\\n\\tsed -e \'s/%2B/+/ig\' -e \'s/%2F/\\\\//ig\' -e \'s/%3D/=/ig\' | \\\\\\n\\tbase64 -d | \\\\\\n\\tprotoc --decode=MigrationPayload OtpMigration.proto \\\\\\n\\t> secrets\\n```\\n\\nIf you retrieve the data from the QR code in another way, you can replace the first line by:\\n\\n```bash\\n# Note the space before `echo`, it prevents the line\\n# to be saved in the command history, as it contains secret data\\n echo \\"<qr-code-data>\\" | \\\\\\n```\\n\\nNow, you can open the `secrets` file and edit it as you want. For each entry, you can rename the `issuer`, or delete it.\\n\\nThen run the following to recreate a QR code and display it on your screen, which you will scan with Google Authenticator using the \\"Import accounts\\" feature present in the settings.\\n\\n```bash\\ncat secrets | \\\\\\n\\tprotoc --encode=MigrationPayload OtpMigration.proto | \\\\\\n\\tbase64 -w 0 | \\\\\\n\\tsed -e \'s/+/%2B/ig\' -e \'s/\\\\//%2F/ig\' -e \'s/=/%3D/ig\' | \\\\\\n\\tsed \'s/^/otpauth-migration:\\\\/\\\\/offline?data=/\' | \\\\\\n\\txargs echo | \\\\\\n\\tqrencode -t utf8 -o -\\n```\\n\\n:::caution\\nKeep in mind that this data is as secret as your passwords. Do not play with QR codes in a public place where you could be seen by a security cameras, or people with phones.\\n:::"},{"id":"archiving-git-branches","metadata":{"permalink":"/blog/archiving-git-branches","editUrl":"https://github.com/zwyx/zwyx.dev/tree/master/blog/2021-10-23-archiving-git-branches/index.mdx","source":"@site/blog/2021-10-23-archiving-git-branches/index.mdx","title":"Tidy up a Git repo by archiving branches","description":"Reduce the amount of branches without necessarily deleting them.","date":"2021-10-23T00:00:00.000Z","tags":[{"inline":true,"label":"git","permalink":"/blog/tags/git"},{"inline":true,"label":"branch","permalink":"/blog/tags/branch"},{"inline":true,"label":"archive","permalink":"/blog/tags/archive"}],"readingTime":2.65,"hasTruncateMarker":true,"authors":[{"name":"Alex","title":"Web developer","email":"alex@zwyx.dev","url":"https://github.com/Zwyx","imageURL":"https://github.com/zwyx.png","key":"alex","page":null}],"frontMatter":{"slug":"archiving-git-branches","title":"Tidy up a Git repo by archiving branches","description":"Reduce the amount of branches without necessarily deleting them.","image":"./branches.webp","authors":["alex"],"tags":["git","branch","archive"]},"unlisted":false,"prevItem":{"title":"Google Authenticator export format","permalink":"/blog/google-authenticator-export-format"},"nextItem":{"title":"Multiple shared password stores with Git and pass","permalink":"/blog/shared-password-stores"}},"content":"import { Image } from \\"@site/src/components/Image\\";\\nimport branches from \\"./branches.webp\\";\\n\\n<Image src={branches} alt=\\"Tree branches\\" />\\n\\nReduce the amount of branches without necessarily deleting them\\n\\n{/* truncate */}\\n\\n:::note\\nThis article contains ideas and suggestions for an more advanced use of Git; it\'s intended for people who already know its basic usage.\\n:::\\n\\n---\\n\\nWhen working on a code base, alone or with a team, we can end up with a lot of branches that are inactive. They are experiments that have never been completed, for instance.\\n\\nThe presence of these forgotten branches can be bothering:\\n\\n- when using the CLI, auto-completion for `git checkout` will be cluttered;\\n- when using an interface such as GitHub, to select a branch in order to create a pull request or run an action, the list will be long;\\n- generally, you may find that having loads of branches in your repo is like having loads _TODOs-that-will-never-be-done_ on your TODO list. Or loads of _\\"in progress\\"_ tickets on a Kanban board.\\n\\nHowever, deleting these branches might not be possible. Some could be useful in the future. Some people in your team might want to delete them while others want to keep them.\\n\\nA solution is to \u201carchive\u201d these branches by storing them separately from the normal git branches. The archived branches won\'t show up in `git branch` anymore, but they will stay available if someone wants to resume work on them.\\n\\n## Git refs\\n\\nGit stores local branches in `refs/heads`. For instance, a branch called branch will be in `refs/heads/branch`.\\n\\nRemote branches are in `refs/remote/<remote-name>`. For instance, `refs/remote/origin/branch`. There are also `refs/tags`, `refs/stash`, `refs/notes`.\\n\\nTo archive a branch, we can place them in a newly created ref, for instance: `refs/experiments`.\\n\\nIf we are in a team we can add a sub-level with the name of the developers: `refs/experiments/<developer-name>`.\\n\\nThe following sections explains the commands allowing us to achieve this.\\n\\n## Archive a branch\\n\\n- Save the branch in the `experiments` ref:\\n\\n  `git update-ref refs/experiments/alice/branch branch`\\n\\n- Push the experiment to the remote:\\n\\n  `git push origin refs/experiments/alice/branch`\\n\\n- Delete the original branch, locally and on the remote:\\n\\n  `git branch -d branch`\\n\\n  `git push -d origin branch`\\n\\n## Restore a branch\\n\\n- Create a branch that points to the same commit than the experiment:\\n\\n  `git checkout -b branch refs/experiments/alice/branch`\\n\\n- Optional, delete the experiment, locally and on the remote:\\n\\n  `git update-ref -d refs/experiments/alice/branch`\\n\\n  `git push -d origin refs/experiments/alice/branch`\\n\\n## Other useful commands\\n\\n- View all experiments:\\n\\n  `git for-each-ref | grep refs/experiments`\\n\\n- Push all experiments to the remote:\\n\\n  `git push origin \\"refs/experiments/*\\"`\\n\\n- Fetch all experiments present on the remote:\\n\\n  `git fetch origin \\"refs/experiments/*:refs/experiments/*\\"`\\n\\n  (or:\\n\\n  `git fetch origin \\"+refs/experiments/\\\\*:refs/experiments/\\\\*\\"`\\n\\n  but careful: **this will erase all experiments present locally**)\\n\\n- See everything that\'s in refs on a remote repository:\\n\\n  `git clone --mirror <repo>`\\n\\n  `cd <repo>`\\n\\n  `git for-each-ref`\\n\\n  Doing this on a GitHub repository which has had pull requests, you will notice that GitHub creates refs/pull and stores all pull requests in it."},{"id":"shared-password-stores","metadata":{"permalink":"/blog/shared-password-stores","editUrl":"https://github.com/zwyx/zwyx.dev/tree/master/blog/2021-06-27-shared-password-stores/index.mdx","source":"@site/blog/2021-06-27-shared-password-stores/index.mdx","title":"Multiple shared password stores with Git and pass","description":"Use pass to set up a complete, shared and segmented, professional password store.","date":"2021-06-27T00:00:00.000Z","tags":[{"inline":true,"label":"password","permalink":"/blog/tags/password"},{"inline":true,"label":"password manager","permalink":"/blog/tags/password-manager"},{"inline":true,"label":"pass","permalink":"/blog/tags/pass"}],"readingTime":6.84,"hasTruncateMarker":true,"authors":[{"name":"Alex","title":"Web developer","email":"alex@zwyx.dev","url":"https://github.com/Zwyx","imageURL":"https://github.com/zwyx.png","key":"alex","page":null}],"frontMatter":{"slug":"shared-password-stores","title":"Multiple shared password stores with Git and pass","description":"Use pass to set up a complete, shared and segmented, professional password store.","image":"./main.webp","authors":["alex"],"tags":["password","password manager","pass"]},"unlisted":false,"prevItem":{"title":"Tidy up a Git repo by archiving branches","permalink":"/blog/archiving-git-branches"},"nextItem":{"title":"NFC on Android with React and TypeScript using Capacitor or Cordova","permalink":"/blog/react-nfc"}},"content":"import { Image } from \\"@site/src/components/Image\\";\\nimport main from \\"./main.webp\\";\\n\\n<Image src={main} legend=\\"Password store layout example\\" />\\n\\nIn this post, we will use `pass` to set up a complete, shared and segmented, professional password store.\\n\\n{/* truncate */}\\n\\n:::note\\nThis post contains ideas and suggestions for a more advanced use of `pass`; it\'s intended for people who already know its basic usage.\\n:::\\n\\n---\\n\\nBefore all, why do I use a trivial command line tool instead of one of the many fancy password managers available?\\n\\nBecause I believe critical things need to be kept simple.\\n\\nThey need to be open source and have proven themselves by being maintained, audited, and used by many.\\n\\n:::info\\nEven a serious security company is capable of inadvertently exposing a backdoor on their users\' machines [allowing remote code execution and the theft of your passwords](https://bugs.chromium.org/p/project-zero/issues/detail?id=693&redir=1) (\u2190 I really recommend the reading of this story).\\n:::\\n\\n`pass` is [one bash script](https://git.zx2c4.com/password-store/tree/src/password-store.sh) relying on [GPG](https://gnupg.org/). Both tools are open and have been used extensively for a while.\\n\\nThere are some GUIs for `pass`, some browser extensions, mobile apps, etc. but choose them carefully: the more we add, the larger the [attack surface](https://github.com/IJHack/QtPass/issues/338) becomes.\\n\\nI use Termux on Android, which provides `pass` in its [packages](https://github.com/termux/termux-packages). It doesn\'t autofill credentials, but apps and websites are good at remembering who you are these days, so I don\'t need to log in often.\\n\\n## Retrieve a password\\n\\nFirst, a little tweak for the retrieval of a password.\\n\\nThe default command \u2014 `pass -c <password-name>` \u2014 outputs the password in the clipboard and clears it after 45 seconds.\\n\\nHowever, I have a clipboard manager that keeps everything I put in the clipboard.\\n\\nTo prevent passwords from being recorded, I wrote a command that outputs them in the _X selection_ instead of the clipboard. To paste them, I click the middle mouse button, instead of using Ctrl-V.\\n\\nTo do that, add the following in your `.zshrc` (you might have to make some modifications if you\'re using a different shell):\\n\\n```bash\\np() {\\n\\t# Insert the password into the X selection\\n\\t# (also called primary, see `man xclip`)\\n\\tpass $1 | head -n 1 | tr -d \\"\\\\n\\" | xclip\\n\\n\\t# Countdown\\n\\tfor i in {5..1}; do\\n\\t\\tprintf \\"\\\\r$i\\"\\n\\t\\tsleep 1\\n\\tdone\\n\\n\\t# Clear the selection\\n\\techo -n \\"\\" | xclip\\n\\n\\techo \\"\\\\r\u2714\\"\\n}\\n\\n# Associate the completer of `pass` to the command `p`, allowing\\n# the Tab key to be used with `p` to autocomplete the passwords names\\ncompdef _pass p\\n\\n# Note: use `p` only to retrieve an existing password,\\n# not with other `pass` commands (`generate`, etc.)\\n```\\n\\nHere it is in action:\\n\\nimport p from \\"./p.gif\\";\\n\\n<Image src={p} alt=\\"The p command\\" />\\n\\n## Set up more than one password store\\n\\nIt\'s possible to have two completely separated password stores by creating a new command for the second one. The new command, `passpro` for instance, will use a different directory:\\n\\n```bash\\npasspro() {\\n\\t# Set a different password store directory,\\n\\t# then run `pass` with all the arguments received by `passpro`\\n\\tPASSWORD_STORE_DIR=~/.password-store-pro pass $@\\n}\\n\\n_passpro() {\\n\\t# Same idea for the completer\\n\\tPASSWORD_STORE_DIR=~/.password-store-pro _pass\\n}\\n\\n# Then we associate the two\\ncompdef _passpro passpro\\n\\n# And we can have the same short command to retrieve a password:\\npp() {\\n\\tPASSWORD_STORE_DIR=~/.password-store-pro p $@\\n}\\n\\ncompdef _passpro pp\\n```\\n\\n:::tip\\nHaving two different pass commands is my preference, but there are other ways to have multiple stores. For instance, you could make use of `.gitignore` or git submodules to have the second store inside the first one.\\n:::\\n\\n## Share a password store\\n\\nWe can share a password store with many people, while still being able to fine tune who has access to what.\\n\\n- We create a subfolder for each team, for instance a `devs` subfolder and a `support` subfolder:\\n\\n```\\n~/.password-store-pro\\n\u251c\u2500\u2500 devs\\n\u2502   \u251c\u2500\u2500 databasePassword\\n\u2502   \u251c\u2500\u2500 serverSshKey\\n\u2502   \u2514\u2500\u2500 stackCredentials\\n\u2514\u2500\u2500 support\\n    \u251c\u2500\u2500 supportPlatformPassword\\n    \u2514\u2500\u2500 supportEmailPassword\\n```\\n\\n- Inside each, we put a `.gpg-id` file listing the PGP key UIDs of the persons having access to the content of this subfolder:\\n\\n```\\n~/.password-store-pro\\n\u251c\u2500\u2500 devs          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502   \u251c\u2500\u2500 .gpg-id \u2192 \u2502 Alice <alice@example.com> \u2502\\n\u2502   \u2502             \u2502 Bob <bob@example.com>     \u2502\\n\u2502   \u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n\u2502   \u251c\u2500\u2500 databasePassword    \\\\\\n\u2502   \u251c\u2500\u2500 serverSshKey         > Each file is encrypted\\n\u2502   \u2514\u2500\u2500 stackCredentials    /  for Alice and Bob\\n\u2514\u2500\u2500 support       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n    \u251c\u2500\u2500 .gpg-id \u2192 \u2502 Alice <alice@example.com> \u2502\\n    \u2502             \u2502 Carl <carl@example.com>   \u2502\\n    \u2502             \u2502 David <david@example.com> \u2502\\n    \u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n    \u251c\u2500\u2500 supportPlatformPassword   \\\\ Each file is encrypted for\\n    \u2514\u2500\u2500 supportEmailPassword      / Alice, Carl and David\\n```\\n\\nAnd that\'s basically it.\\n\\nThere are a few other things to help us:\\n\\n- In the root directory, a `.public-keys` folder contains the public PGP keys of all the persons having access to the store. That allows the creation of new passwords that will be decryptable by the persons/teams we want.\\n\\n- The `.gpg-id` file in the root directory lists who has access to the secrets in this directory \u2014 and any subfolder which doesn\'t have its own `.gpg-id`. We don\'t use it in this example.\\n\\n- Finally, the bash script `encrypt.sh` is used to display detailed information about the password store, and to reencrypt it when a new user is given access to the store. Indeed, when a new user is added, every passwords he will have access to needs to be reencrypted for his public key. This process is explain later in this article.\\n\\nSo here\'s our complete, shared and segmented, professional password store:\\n\\n```\\n~/.password-store-pro\\n\u251c\u2500\u2500 .public-keys\\n\u2502   \u251c\u2500\u2500 alice.asc\\n\u2502   \u251c\u2500\u2500 bob.asc\\n\u2502   \u251c\u2500\u2500 carl.asc\\n\u2502   \u2514\u2500\u2500 david.asc\\n\u251c\u2500\u2500 devs          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502   \u251c\u2500\u2500 .gpg-id \u2192 \u2502 Alice <alice@example.com> \u2502\\n\u2502   \u2502             \u2502 Bob <bob@example.com>     \u2502\\n\u2502   \u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n\u2502   \u251c\u2500\u2500 databasePassword\\n\u2502   \u251c\u2500\u2500 serverSshKey\\n\u2502   \u2514\u2500\u2500 stackCredentials\\n\u251c\u2500\u2500 support       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502   \u251c\u2500\u2500 .gpg-id \u2192 \u2502 Alice <alice@example.com> \u2502\\n\u2502   \u2502             \u2502 Carl <carl@example.com>   \u2502\\n\u2502   \u2502             \u2502 David <david@example.com> \u2502\\n\u2502   \u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n\u2502   \u251c\u2500\u2500 supportPlatformPassword\\n\u2502   \u2514\u2500\u2500 supportEmailPassword\\n\u251c\u2500\u2500 .gpg-id\\n\u2514\u2500\u2500 encrypt.sh\\n```\\n\\nThe content of encrypt.sh can be found [here](https://gist.github.com/Zwyx/aecea360db2c50a058a9b1f0c5287b45).\\n\\nNow, let\'s see how to use the password store.\\n\\n## Add a new password to the shared store\\n\\nNow that we have the structure of our shared store, let\'s create a password.\\n\\n- First, we import the all public keys to our keyring:\\n\\n```bash\\ngpg --import ~/.password-store-pro/.public-keys/*.asc\\n```\\n\\n- And we trust them \u2014 the following needs to be done for each keys:\\n\\n```bash\\ngpg --edit-key \\"<key-uid>\\"\\ngpg> trust\\nYour decision? 5\\ngpg> quit\\n```\\n\\n- Optionally, we create a new Git branch. As the password store is a Git repository, we can run Git commands on this repository with `pass git`, for instance:\\n\\n```bash\\npasspro git checkout -b new-password\\n```\\n\\n- Choose in which subfolder to put the new password, and generate it:\\n\\n```bash\\npasspro generate -n devs/cloudPlatformCredentials 20\\n```\\n\\n- Push the branch and create a pull request.\\n\\n## Give access to the password store to a new user\\n\\nAs stated before, when a new user is added, every passwords he will have access to needs to be reencrypted for his public key.\\n\\n- First, we add the user\'s public key to the `.public-keys` directory.\\n\\n- Then, we import it to our keyring:\\n\\n```bash\\ngpg --import .public-keys/*.asc\\n```\\n\\n- We find its uid:\\n\\n```bash\\ngpg --list-keys\\n```\\n\\nFor instance, the uid can be: `Elie <elie@example.com>`\\n\\n- We trust the public key:\\n\\n```bash\\ngpg --edit-key \\"Elie <elie@example.com>\\"\\ngpg> trust\\nYour decision? 5\\ngpg> quit\\n```\\n\\n- We add the key\'s uid in the `.gpg-id` file of each subfolder the new user needs to have access to; for instance, let\'s say that the new user is a developer, we add the key\'s uid in `devs/.gpg-id`:\\n\\n```bash\\nAlice <alice@example.com>\\nBob <bob@example.com>\\nElie <elie@example.com>\\n```\\n\\n- We now reencrypt all passwords and secrets for the new user:\\n\\n```bash\\n./encrypt.sh devs\\n```\\n\\nThis will list the persons for whom the `devs` subfolder will be encrypted, and ask you to confirm:\\n\\n```bash\\nPassword store root directory:\\n\\t\'/home/user/.password-store-pro\'\\n\\n1 subfolders will be encrypted.\\n\\n\'devs\' will be encrypted for:\\n\\tAlice <alice@example.com>\\n\\tBob <bob@example.com>\\n\\tElie <elie@example.com>\\n\\nProceed? [y/N]\\n```\\n\\n`./encrypt.sh` can also be run without any arguments, to reencrypt the whole store. However, remember that you need access to a password in order to be able to encrypt it for a new user, as you need to decrypt it first.\\n\\n:::note\\nDecrypting passwords stays as easy than it is with a personal password store. Note that Windows users who only need read access to the passwords can install Gpg4win\u200a-\u200ainstead of a non-official version of Pass.\\n:::\\n\\n---\\n\\nI hope you enjoyed this article, have fun with Pass!"},{"id":"react-nfc","metadata":{"permalink":"/blog/react-nfc","editUrl":"https://github.com/zwyx/zwyx.dev/tree/master/blog/2019-10-05-react-nfc/index.mdx","source":"@site/blog/2019-10-05-react-nfc/index.mdx","title":"NFC on Android with React and TypeScript using Capacitor or Cordova","description":"Hybrid mobile apps are a great way to add native mobile features to an existing responsive web app.","date":"2019-10-05T00:00:00.000Z","tags":[{"inline":true,"label":"nfc","permalink":"/blog/tags/nfc"},{"inline":true,"label":"typescript","permalink":"/blog/tags/typescript"},{"inline":true,"label":"react","permalink":"/blog/tags/react"},{"inline":true,"label":"capacitor","permalink":"/blog/tags/capacitor"},{"inline":true,"label":"cordova","permalink":"/blog/tags/cordova"}],"readingTime":9.09,"hasTruncateMarker":true,"authors":[{"name":"Alex","title":"Web developer","email":"alex@zwyx.dev","url":"https://github.com/Zwyx","imageURL":"https://github.com/zwyx.png","key":"alex","page":null}],"frontMatter":{"slug":"react-nfc","title":"NFC on Android with React and TypeScript using Capacitor or Cordova","description":"Hybrid mobile apps are a great way to add native mobile features to an existing responsive web app.","image":"./react-nfc.webp","authors":["alex"],"tags":["nfc","typescript","react","capacitor","cordova"]},"unlisted":false,"prevItem":{"title":"Multiple shared password stores with Git and pass","permalink":"/blog/shared-password-stores"}},"content":"import { Image } from \\"@site/src/components/Image\\";\\nimport reactNfc from \\"./react-nfc.webp\\";\\n\\n:::danger[Warning: this article is old!]\\nThis article has been written in 2019. I stopped working with NFC on mobile a few years later.\\n:::\\n\\n<Image src={reactNfc} alt=\\"React NFC\\" />\\n\\n[Ionic Capacitor](https://capacitor.ionicframework.com/) and [Apache Cordova](https://cordova.apache.org/) are two common wrappers to create a hybrid mobile application from a web application. The main advantage over a native mobile app is the re-usability of the code \u2014 and the development languages being HTML, CSS, and JavaScript, if we like them.\\n\\n{/* truncate */}\\n\\nHowever, hybrid apps are not always the best choice and some research is necessary to determine which technology is best for a particular purpose.\\n\\n:::note\\nOne thing to keep in mind though, is that using a mobile wrapper to create a hybrid app which is nothing more than a shell for a website, is [not well accepted](https://stackoverflow.com/questions/5478848/does-apple-reject-mobile-web-shell-applications).\\n:::\\n\\n---\\n\\nLet\'s say we have a nice responsive web app which works already great on a mobile browser, and which would be even greater if it could use NFC features on mobile devices.\\n\\nAs we cannot access NFC from a web browser ([yet](https://w3c.github.io/web-nfc/)), we need to create a mobile app.\\n\\nAs our web app is already designed to be displayed well on small screens (responsive), creating a hybrid mobile app from it will be much easier and quicker than recreating a native mobile app from scratch (or more than one: one for each platform we want to support\u2026).\\n\\nTo demonstrate this, we will start by [creating a React app](https://create-react-app.dev/) \u2014 with TypeScript \u2014 add the [PhoneGap NFC plugin](https://github.com/chariotsolutions/phonegap-nfc), then wrap our app with Capacitor or Cordova. We will need Node and npm (use a Node version manager, like [nvm](https://github.com/nvm-sh/nvm)), the Android SDK and Android Studio.\\n\\n## Web App\\n\\nFirst, we create a new React app by running:\\n\\n```bash\\nnpx create-react-app react-nfc --typescript\\n```\\n\\n:::info\\n`npx` allows to execute npm package binaries without having to install them.\\n:::\\n\\nThen we jump in the newly created folder and install PhoneGap NFC and its types for TypeScript:\\n\\n```bash\\ncd react-nfc\\nnpm i phonegap-nfc\\nnpm i --save-dev @types/phonegap-nfc\\n```\\n\\nThe PhoneGap NFC stuff will be accessible globally, so we don\'t need any imports in our code.\\n\\nNow we open `src/App.tsx` and we replace its content by the following code, which is going to initialise NFC, invite the user to open the phone settings if NFC is not enabled, and read the content of an NFC tag (PhoneGap NFC offers plenty of other features documented [here](https://github.com/chariotsolutions/phonegap-nfc)):\\n\\n```tsx title=\\"src/App.tsx\\"\\nimport React from \\"react\\";\\nimport \\"./App.css\\";\\n\\n/** Type for the possible steps of the app */\\ntype TStep =\\n\\t| \\"initializing\\"\\n\\t| \\"noNfc\\"\\n\\t| \\"nfcNotEnabled\\"\\n\\t| \\"waitingForNfcEnabled\\"\\n\\t| \\"waitingForTag\\"\\n\\t| \\"cancelled\\"\\n\\t| \\"tagRead\\";\\n\\nconst App: React.FC = () => {\\n\\tconst [step, setStep] = React.useState<TStep>(\\"initializing\\");\\n\\tconst [tagContent, setTagContent] = React.useState(\\"\\");\\n\\n\\t// Initialize NFC when the app is started\\n\\tReact.useEffect(initializeNfc, []);\\n\\n\\tfunction initializeNfc() {\\n\\t\\t// If nfc is undefined, NFC is not available on this device, or\\n\\t\\t// the app is running in a web browser\\n\\t\\tif (typeof nfc !== \\"undefined\\") {\\n\\t\\t\\t// Register an event listener\\n\\t\\t\\tnfc.addNdefListener(\\n\\t\\t\\t\\tonNdefEvent, // The callback function for the event listener\\n\\t\\t\\t\\t() => setStep(\\"waitingForTag\\"), // Success \u2192 We\'re waiting for an event\\n\\t\\t\\t\\t() => setStep(\\"nfcNotEnabled\\"), // Error \u2192 NFC must not be enabled\\n\\t\\t\\t);\\n\\t\\t} else {\\n\\t\\t\\tsetStep(\\"noNfc\\");\\n\\t\\t}\\n\\t}\\n\\n\\tfunction onGoToSettingsClick() {\\n\\t\\tif (typeof nfc !== \\"undefined\\") {\\n\\t\\t\\t// Ask the device to open the NFC settings for the user\\n\\t\\t\\tnfc.showSettings(\\n\\t\\t\\t\\t() => setStep(\\"waitingForNfcEnabled\\"),\\n\\t\\t\\t\\t() => alert(\\"An error occurred while trying to open the NFC Settings.\\"),\\n\\t\\t\\t);\\n\\t\\t}\\n\\t}\\n\\n\\tfunction onNdefEvent(e: PhoneGapNfc.TagEvent) {\\n\\t\\t// Unregister the event listener\\n\\t\\tnfc.removeNdefListener(onNdefEvent);\\n\\n\\t\\tsetTagContent(\\n\\t\\t\\t// Retrieve the payload of the tag and decode it\\n\\t\\t\\t// https://www.oreilly.com/library/view/beginning-nfc/9781449324094/ch04.html\\n\\t\\t\\tndef.textHelper.decodePayload(\\n\\t\\t\\t\\t(e as PhoneGapNfc.NdefTagEvent).tag.ndefMessage[0].payload,\\n\\t\\t\\t),\\n\\t\\t);\\n\\n\\t\\tsetStep(\\"tagRead\\");\\n\\t}\\n\\n\\tfunction onStopClick() {\\n\\t\\tif (typeof nfc !== \\"undefined\\") {\\n\\t\\t\\t// Unregister the event listener\\n\\t\\t\\tnfc.removeNdefListener(onNdefEvent);\\n\\t\\t}\\n\\n\\t\\tsetStep(\\"cancelled\\");\\n\\t}\\n\\n\\treturn (\\n\\t\\t<div className=\\"nfc\\">\\n\\t\\t\\t{step === \\"initializing\\" ? (\\n\\t\\t\\t\\t<div>Initializing...</div>\\n\\t\\t\\t) : step === \\"noNfc\\" ? (\\n\\t\\t\\t\\t<div>\\n\\t\\t\\t\\t\\tThe device you are using doesn\'t appear to have NFC; or, the\\n\\t\\t\\t\\t\\tPhoneGap-NFC plugin hasn\'t been set up correctly.\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t) : step === \\"nfcNotEnabled\\" ? (\\n\\t\\t\\t\\t<div>\\n\\t\\t\\t\\t\\t<div>\\n\\t\\t\\t\\t\\t\\tNFC is not enabled on your device. Click the button bellow to open\\n\\t\\t\\t\\t\\t\\tyour device\'s settings, then activate NFC.\\n\\t\\t\\t\\t\\t</div>\\n\\t\\t\\t\\t\\t<button onClick={onGoToSettingsClick}>Go to NFC Settings</button>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t) : step === \\"waitingForNfcEnabled\\" ? (\\n\\t\\t\\t\\t<div>\\n\\t\\t\\t\\t\\t<div>Please click the button below once you have enabled NFC.</div>\\n\\t\\t\\t\\t\\t<button onClick={initializeNfc}>Initialize NFC Reader</button>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t) : step === \\"waitingForTag\\" ? (\\n\\t\\t\\t\\t<div>\\n\\t\\t\\t\\t\\t<div>Scan a NFC Tag to see its content</div>\\n\\t\\t\\t\\t\\t<button onClick={onStopClick}>Stop NFC Reader</button>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t) : step === \\"tagRead\\" ? (\\n\\t\\t\\t\\t<div>\\n\\t\\t\\t\\t\\t<div>Tag scanned! Here it\'s content:</div>\\n\\t\\t\\t\\t\\t<div>{tagContent}</div>\\n\\t\\t\\t\\t\\t<button onClick={onStopClick}>Stop NFC Reader</button>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t) : (\\n\\t\\t\\t\\t<div>\\n\\t\\t\\t\\t\\t<div>Bye!</div>\\n\\t\\t\\t\\t</div>\\n\\t\\t\\t)}\\n\\t\\t</div>\\n\\t);\\n};\\n\\nexport default App;\\n```\\n\\nWe add some styling in `App.css`:\\n\\n```css title=\\"App.css\\"\\n.nfc {\\n\\theight: 100vh;\\n\\twidth: 100vw;\\n\\tbackground-color: #21252b;\\n\\tcolor: #abb2bf;\\n\\tdisplay: flex;\\n\\tflex-direction: column;\\n\\tjustify-content: center;\\n\\ttext-align: center;\\n}\\n\\n.nfc div {\\n\\tpadding: 8px 16px;\\n}\\n\\nbutton {\\n\\tmargin: 16px;\\n\\tborder: none;\\n\\tborder-radius: 3px;\\n\\tpadding: 8px 12px;\\n\\tbackground-color: #61afef;\\n\\tcolor: #21252b;\\n\\tcursor: pointer;\\n}\\n```\\n\\nWe can now build the project:\\n\\n```bash\\nnpm run build\\n```\\n\\nAnd that\'s it for our app. The full project can be found [here](https://github.com/Zwyx/react-nfc).\\n\\n## Mobile Wrappers\\n\\nNow, we are going to wrap our web app to create an Android one. Once with Capacitor, once with Cordova (this is twice the same thing, we only do it to show case the two solutions).\\n\\n### Preparing the Android device\\n\\n- Activate the Developer Mode: open the Android settings, go in **System** \u2192 **About device**, then tap **Build number** quickly seven times.\\n- Activate USB Debugging: in **Settings** \u2192 **System** \u2192 **Developer options**, turn **USB debugging** ON.\\n- Connect the device to the computer.\\n- If a notification **USB charging this device** appears, tap on it and select **Transfer files**.\\n- Answer **OK** when Android asks **Allow USB debugging?**.\\n\\n### Capacitor\\n\\nWe run the following commands to install Capacitor, initialise it for our web app (our built app files are located in the `build` folder), and add the Android platform to our project:\\n\\n```bash\\nnpm i @capacitor/core @capacitor/cli\\nnpx cap init --web-dir build\\nnpx cap add android\\n```\\n\\n:::info\\nIf an error occurs, see the first point in the [**Notes**](#notes) section below.\\n:::\\n\\nWe can now start Android Studio, open the newly created `android` folder as a project, wait for the scripts execution to finish, then click **Run** \u2192 **Run \'app\'** to execute our app on our device.\\n\\nimport nfcUnavailable from \\"./nfc-unavailable.webp\\";\\n\\n<div style={{ textAlign: \\"center\\" }}>\\n\\n<Image\\n\\tsrc={nfcUnavailable}\\n\\twidth=\\"80%\\"\\n\\tlegend=\\"Our web app on an Android device with NFC not enabled\\"\\n/>\\n\\n</div>\\n\\nFrom now on, if we make changes to our web app, we just need to run the following two commands to rebuild the app and update the Capacitor project:\\n\\n```bash\\nnpm run build\\nnpx cap sync\\n```\\n\\n(If Android Studio is a bit lost, **Project** \u2192 **Rebuild** might help \u2014 if it is still lost, closing the project and reopen the `android` folder should work. Likewise, unplugging and plugging back the device might sometimes help is the Android debugger doesn\'t recognise it.)\\n\\n#### Resources with Capacitor\\n\\nThe app logo and splash screen are located in the `android/app/src/main/res folder`.\\n\\nTo create a new logo, in Android Studio, right click on the `res` folder then select **New** \u2192 **Image Asset**.\\n\\nTo change the splash screen, generate the images using a tool like [this one](https://apetools.webprofusion.com/), then place them in the `res` folder.\\n\\n### Cordova\\n\\nCordova requires a few tweaks in the web app itself.\\n\\nFirst, we need to replace the following line in `src/index.tsx`:\\n\\n```tsx\\nReactDOM.render(<App />, document.getElementById(\\"root\\"));\\n```\\n\\nby:\\n\\n```tsx\\ndocument.addEventListener(\\n\\t\\"deviceready\\",\\n\\t() => ReactDOM.render(<App />, document.getElementById(\\"root\\")),\\n\\tfalse,\\n);\\n```\\n\\nThen, we need to add the following parameter in `package.json` \u2014 at the same level of `name`, `version`, etc.:\\n\\n```json\\n\\"homepage\\" : \\"./\\",\\n```\\n\\nWe can now rebuild the app:\\n\\n```bash\\nnpm run build\\n```\\n\\nNow, we need to set up our environment:\\n\\n- Create the `ANDROID_SDK_ROOT` variable\\n- Add the `bin` folder of graddle in the `PATH`\\n- Make sure the graddle executable is actually executable\\n\\nReplace the `<...>` in the following commands before running them:\\n\\n```bash\\nexport ANDROID_SDK_ROOT=<path-to-the-android-sdk>\\nexport PATH=$PATH:<path-to-android-studio>/gradle/gradle-<version>/bin\\nchmod +x <path-to-android-studio>/gradle/gradle-<version>/bin/gradle\\n```\\n\\nWe can now create our Cordova project:\\n\\n```bash\\nnpx cordova create Cordova com.example ReactNfc\\ncd Cordova\\nnpx cordova plugin add phonegap-nfc\\nnpx cordova platform add android\\n```\\n\\n:::info\\nIf an error occurs, see the second point in the [**Notes**](#notes) section below.\\n:::\\n\\nWe place our web app in the Cordova project by copying the content of the `build` folder in the `Cordova/www` folder (after having deleted everything in `Cordova/www`). We also need to add the following line in `index.html`:\\n\\n```html\\n<script src=\\"cordova.js\\"><\/script>\\n```\\n\\nAs `index.html` is minified, to make it simple, we just paste this line at the end of the file, just before the `</body></html>` tags. So the file ends by:\\n\\n```html\\n<script src=\\"cordova.js\\"><\/script></body></html>\\n```\\n\\nThat\'s it! Cordova requires a few more tweaks than Capacitor, but we now just have to run:\\n\\n```bash\\nnpx cordova run\\n```\\n\\nto launch our app on our device!\\n\\n---\\n\\nHopefully this article has given you the basics to create a hybrid mobile app from a web app and use a native feature with it such as NFC. Happy coding!\\n\\nOh, and if you are going to use a package often, you might want to install it instead of using `npx`, especially Cordova which can take a while to start. It\'s recommended to install it locally in the project folder.\\n\\nTo do so, first create the Cordova project with `npx` then jump in the `Cordova` folder and run:\\n\\n```bash\\nnpm i cordova\\n```\\n\\nNow open the file `package.json` \u2014 still in the Cordova folder \u2014 and add the following script in the `\\"scripts\\"` section:\\n\\n```json\\n\\"cordova\\": \\"node_modules/cordova/bin/cordova\\"\\n```\\n\\nYou can now run, for instance:\\n\\n```bash\\nnpm run cordova run\\n```\\n\\nTo install Cordova globally, you can run:\\n\\n```bash\\nsudo npm install -g cordova\\n```\\n\\n## Notes\\n\\n- An error occurred when I was initialising Capacitor with the PhoneGap NFC plugin. I had to open the file `node_modules/@capacitor/cli/dist/android/update.js` and replace line `208` from:\\n\\n```js\\nconst pathParts = getPathParts(configElement.$.parent);\\n```\\n\\nto:\\n\\n```js\\nconst pathParts = getPathParts(\\n\\tconfigElement.$.parent || configElement.$.target,\\n);\\n```\\n\\nThis problem [has been fixed](https://github.com/ionic-team/capacitor/pull/1794/files) already, it will probably be pushed on NPM with the next update of Capacitor.\\n\\n- An error occurred when I was initialising Cordova with the PhoneGap NFC plugin. I had to open the file `Cordova/plugins/phonegap-nfc/plugin.xml` and comment out the following section (starting at line `39`):\\n\\n```xml\\n<edit-config file=\\"AndroidManifest.xml\\" target=\\"/manifest/uses-sdk\\" mode=\\"merge\\">\\n    <uses-sdk android:minSdkVersion=\\"19\\" />\\n</edit-config>\\n```\\n\\nthen delete the folder `Cordova/platforms/android` and execute again:\\n\\n```bash\\nnpx cordova platform add android\\n```\\n\\nThis error [has been identified](https://github.com/chariotsolutions/phonegap-nfc/issues/371)."}]}}')}}]);